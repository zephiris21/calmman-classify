# ê¸°ë³¸ CNNìœ¼ë¡œ ì–¼êµ´ í‘œì • ì´ì§„ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
# ì‚¬ì „í•™ìŠµ ì—†ì´ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ëŠ” ë°©ì‹

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import albumentations as A
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from tqdm import tqdm
import random

# ëœë¤ ì‹œë“œ ê³ ì •
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)

print("=== ğŸ¯ ê¸°ë³¸ CNN ì´ì§„ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ===")
print("ì‚¬ì „í•™ìŠµ ì—†ì´ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ëŠ” ë°©ì‹")

# =================================
# 1. ë°ì´í„° ë¡œë”©
# =================================
def load_images_robust(folder_path, label, max_images=None):
    """ë” ê°•ë ¥í•œ ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜"""
    from PIL import Image
    images = []
    labels = []
    failed_files = []
    
    if not os.path.exists(folder_path):
        print(f"âŒ {folder_path} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return images, labels
    
    extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
    all_files = os.listdir(folder_path)
    image_files = [f for f in all_files if f.lower().endswith(extensions)]
    
    print(f"ğŸ“ {os.path.basename(folder_path)} í´ë”:")
    print(f"   ì „ì²´ íŒŒì¼: {len(all_files)}ê°œ")
    print(f"   ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    
    if max_images and len(image_files) > max_images:
        image_files = image_files[:max_images]
        print(f"   ì²˜ë¦¬ ëŒ€ìƒ: {len(image_files)}ê°œ (ì œí•œë¨)")
    
    for fname in tqdm(image_files, desc=f"Loading {os.path.basename(folder_path)}"):
        img_path = os.path.join(folder_path, fname)
        
        try:
            # ë°©ë²• 1: OpenCV
            img = cv2.imread(img_path)
            
            if img is None:
                # ë°©ë²• 2: PIL (í•œê¸€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
                pil_img = Image.open(img_path)
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            
            if img is None or img.shape[0] == 0 or img.shape[1] == 0:
                failed_files.append(fname)
                continue
                
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (224, 224))
            img = img.astype('float32') / 255.0
            
            images.append(img)
            labels.append(label)
            
        except Exception as e:
            failed_files.append(f"{fname}: {str(e)}")
            continue
    
    print(f"   âœ… ì„±ê³µ: {len(images)}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
    
    if failed_files:
        print(f"   ì‹¤íŒ¨ íŒŒì¼ë“¤: {failed_files[:3]}...")  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
    
    return images, labels

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
base_path = r'D:\my_projects\calmman-facial-classification\data\processed'
teasing_path = os.path.join(base_path, 'teasing')
non_teasing_path = os.path.join(base_path, 'non_teasing')

print("\n=== ğŸ“ ë°ì´í„° ë¡œë”© ===")
# ë¹„ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 0)
X_non_teasing, y_non_teasing = load_images_robust(non_teasing_path, 0)

# ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 1)
X_teasing, y_teasing = load_images_robust(teasing_path, 1)

# ë°ì´í„° í•©ì¹˜ê¸°
X = X_non_teasing + X_teasing
y = y_non_teasing + y_teasing

print(f"ë¡œë”© ì™„ë£Œ:")
print(f"  ë¹„ì•½ì˜¬ë¦¬ê¸°: {len(X_non_teasing)}ê°œ")
print(f"  ì•½ì˜¬ë¦¬ê¸°: {len(X_teasing)}ê°œ")
print(f"  ì´ ì´ë¯¸ì§€: {len(X)}ê°œ")

if len(X) == 0:
    print("âŒ ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# =================================
# 2. ì›ë³¸ ë°ì´í„° ë¶„í•  (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
# =================================
print(f"\n=== âœ‚ï¸ ì›ë³¸ ë°ì´í„° ë¶„í•  ===")

X_raw = np.array(X)
y_raw = np.array(y)

print(f"ì›ë³¸ ë°ì´í„°: {X_raw.shape}")
print(f"ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_raw)}")

# ì›ë³¸ ë°ì´í„°ë¥¼ ë¨¼ì € ë¶„í• 
X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(
    X_raw, y_raw, test_size=0.2, random_state=SEED, stratify=y_raw
)

print(f"ì›ë³¸ í›ˆë ¨ ë°ì´í„°: {X_train_raw.shape}")
print(f"ì›ë³¸ ê²€ì¦ ë°ì´í„°: {X_val_raw.shape}")
print(f"ì›ë³¸ í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train_raw)}")
print(f"ì›ë³¸ ê²€ì¦ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_val_raw)}")

# =================================
# 3. ë°ì´í„° ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ!)
# =================================
def augment_data_simple(X_array, y_array, target_per_class=250):
    """í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°•í•˜ëŠ” í•¨ìˆ˜"""
    
    class_0_indices = np.where(y_array == 0)[0]
    class_1_indices = np.where(y_array == 1)[0]
    
    class_0_data = [X_array[i] for i in class_0_indices]
    class_1_data = [X_array[i] for i in class_1_indices]
    
    print(f"\n=== ğŸ”„ í›ˆë ¨ ë°ì´í„° ì¦ê°• ===")
    print(f"ì¦ê°• ì „: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(class_0_data)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(class_1_data)}ê°œ")
    
    
    # ì–¼êµ´ í‘œì •ì— ì í•©í•œ ì¦ê°•
    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.5),
        A.GaussNoise(var_limit=(10, 50), p=0.3),
    ])

    final_class_0 = class_0_data.copy()
    final_class_1 = class_1_data.copy()

    # ë¹„ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_0_data) < target_per_class:
        need_count = target_per_class - len(class_0_data)
        print(f"ë¹„ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_0_data[i % len(class_0_data)]
            # uint8ë¡œ ë³€í™˜ (Albumentations ìš”êµ¬ì‚¬í•­)
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜ [0,1] ë²”ìœ„
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_0.append(aug_img)

    # ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_1_data) < target_per_class:
        need_count = target_per_class - len(class_1_data)
        print(f"ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_1_data[i % len(class_1_data)]
            # uint8ë¡œ ë³€í™˜
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_1.append(aug_img)
    
    # ìµœì¢… ë°ì´í„°
    final_X = final_class_0 + final_class_1
    final_y = [0] * len(final_class_0) + [1] * len(final_class_1)
    
    print(f"ì¦ê°• í›„: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(final_class_0)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(final_class_1)}ê°œ")
    print(f"ì´ í›ˆë ¨ ë°ì´í„°: {len(final_X)}ê°œ")
    
    return final_X, final_y

# í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°• (ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ìœ ì§€!)
X_train_aug, y_train_aug = augment_data_simple(X_train_raw, y_train_raw, target_per_class=250)

# =================================
# 4. ìµœì¢… ë°ì´í„° ì¤€ë¹„
# =================================
print(f"\n=== ğŸ“¦ ìµœì¢… ë°ì´í„° ì¤€ë¹„ ===")

# í›ˆë ¨ ë°ì´í„°: ì¦ê°•ëœ ë°ì´í„° ì‚¬ìš©
X_train = np.array(X_train_aug)
y_train = np.array(y_train_aug)

# ê²€ì¦ ë°ì´í„°: ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©
X_val = X_val_raw
y_val = y_val_raw

print(f"ìµœì¢… í›ˆë ¨ ë°ì´í„°: {X_train.shape}")
print(f"ìµœì¢… ê²€ì¦ ë°ì´í„°: {X_val.shape}")
print(f"ìµœì¢… í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train)}")
print(f"ìµœì¢… ê²€ì¦ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_val)}")

print(f"âœ… ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ê²€ì¦ ë°ì´í„°ëŠ” í›ˆë ¨ ì¤‘ ë³¸ ì  ì—†ëŠ” ì›ë³¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©")

# =================================
# 5. ê¸°ë³¸ CNN ëª¨ë¸ êµ¬ì„±
# =================================
print(f"\n=== ğŸ—ï¸ ê¸°ë³¸ CNN ëª¨ë¸ êµ¬ì„± ===")

model = keras.Sequential([
    # ì…ë ¥ ì •ê·œí™” (ì´ë¯¸ ì •ê·œí™”í–ˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ)
    layers.Rescaling(1.0, input_shape=(224, 224, 3)),
    
    # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(2),
    
    # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(2),
    
    # ì„¸ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
    layers.Conv2D(128, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(2),
    
    # ë¶„ë¥˜ í—¤ë“œ
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')  # ì´ì§„ë¶„ë¥˜
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['binary_accuracy']
)

# ëª¨ë¸ ìš”ì•½
print("ëª¨ë¸ êµ¬ì¡°:")
model.summary()

# =================================
# 6. í•™ìŠµ
# =================================
print(f"\n=== ğŸš€ ëª¨ë¸ í•™ìŠµ ===")

# ì½œë°± ì„¤ì •
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7
    )
]

# í•™ìŠµ ì‹¤í–‰
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,
    batch_size=32,
    callbacks=callbacks,
    verbose=1
)

# =================================
# 7. ì„±ëŠ¥ í‰ê°€
# =================================
print(f"\n=== ğŸ“Š ì„±ëŠ¥ í‰ê°€ ===")

# ìµœì¢… í‰ê°€
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {val_accuracy:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred_prob = model.predict(X_val, verbose=0)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# ë¶„ë¥˜ ë³´ê³ ì„œ
classes = ['non_teasing', 'teasing']
print(f"\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_val, y_pred, target_names=classes))

# í˜¼ë™ í–‰ë ¬
print(f"\ní˜¼ë™ í–‰ë ¬:")
cm = confusion_matrix(y_val, y_pred)
print(cm)

# ì˜ˆì¸¡ ë¶„í¬ í™•ì¸
print(f"\nì˜ˆì¸¡ ë¶„í¬:")
print(f"ì˜ˆì¸¡ í™•ë¥  ë²”ìœ„: {y_pred_prob.min():.4f} ~ {y_pred_prob.max():.4f}")
print(f"ì˜ˆì¸¡ í™•ë¥  í‘œì¤€í¸ì°¨: {y_pred_prob.std():.4f}")
print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_pred)}")

# =================================
# 8. ê²°ê³¼ ì‹œê°í™”
# =================================
print(f"\n=== ğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ===")

# í•™ìŠµ ê³¼ì • ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# ì •í™•ë„ ê·¸ë˜í”„
axes[0].plot(history.history['binary_accuracy'], label='Training Accuracy')
axes[0].plot(history.history['val_binary_accuracy'], label='Validation Accuracy')
axes[0].axhline(y=0.5, color='r', linestyle='--', label='Random Baseline')
axes[0].set_title('Model Accuracy')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend()
axes[0].grid(True)

# ì†ì‹¤ ê·¸ë˜í”„
axes[1].plot(history.history['loss'], label='Training Loss')
axes[1].plot(history.history['val_loss'], label='Validation Loss')
axes[1].set_title('Model Loss')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()
plt.show()

# =================================
# 9. ê²°ê³¼ ìš”ì•½
# =================================
print(f"\n=== ğŸ¯ ê²°ê³¼ ìš”ì•½ ===")
print(f"âœ… ì‚¬ì „í•™ìŠµ ì—†ëŠ” ê¸°ë³¸ CNN ê²°ê³¼:")
print(f"   - ìµœì¢… ê²€ì¦ ì •í™•ë„: {val_accuracy:.1%}")
print(f"   - í•™ìŠµ ì—í¬í¬: {len(history.history['loss'])}íšŒ")
print(f"   - ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {y_pred_prob.std():.4f}")

if val_accuracy > 0.7:
    print(f"ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥! ê¸°ë³¸ CNNë§Œìœ¼ë¡œë„ ì¢‹ì€ ê²°ê³¼")
elif val_accuracy > 0.6:
    print(f"ğŸ‘ ê´œì°®ì€ ì„±ëŠ¥! ì „ì´í•™ìŠµìœ¼ë¡œ ë” ê°œì„  ê°€ëŠ¥")
elif val_accuracy > 0.5:
    print(f"âš ï¸ ëœë¤ë³´ë‹¤ëŠ” ë‚˜ìŒ. ëª¨ë¸ ê°œì„  í•„ìš”")
else:
    print(f"âŒ ì„±ëŠ¥ ë¶€ì¡±. ë°ì´í„°ë‚˜ ëª¨ë¸ ì¬ê²€í†  í•„ìš”")

print(f"\nì „ì´í•™ìŠµê³¼ ë¹„êµí•´ë³´ì‹œê² ì–´ìš”? ğŸ¤”")
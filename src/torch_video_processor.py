#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import cv2
import yaml
import time
import json
import logging
import threading
import queue
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional

import numpy as np
from PIL import Image

from mtcnn_wrapper import FaceDetector
from pytorch_classifier import TorchFacialClassifier


class TorchVideoProcessor:
    """
    PyTorch ê¸°ë°˜ ì¹¨ì°©ë§¨ í‚¹ë°›ëŠ” ìˆœê°„ íƒì§€ë¥¼ ìœ„í•œ ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œ
    """
    
    def __init__(self, config_path: str = "../config/config_torch.yaml"):
        """
        ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config(config_path)
        
        # ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._setup_logging()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë³€ìˆ˜
        self.stats = {
            'frames_processed': 0,
            'faces_detected': 0,
            'angry_moments': 0,
            'processing_start_time': None,
            'last_stats_time': time.time(),
            'batch_count': 0,
            'total_inference_time': 0
        }
        
        # ì¢…ë£Œ í”Œë˜ê·¸ ì¶”ê°€
        self.stop_flag = False
        self.face_detection_done = False
        self.classification_done = False
        
        # í ìƒì„±
        self.frame_queue = queue.Queue(maxsize=self.config['performance']['max_queue_size'])
        self.face_queue = queue.Queue(maxsize=self.config['performance']['max_queue_size'])
        self.result_queue = queue.Queue()
        
        # ì–¼êµ´ íƒì§€ê¸° ì´ˆê¸°í™”
        self._init_face_detector()
        
        # PyTorch ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ
        self._load_classifier()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_output_dirs()
        
        self.logger.info("âœ… TorchVideoProcessor ì´ˆê¸°í™” ì™„ë£Œ")
        self._print_config_summary()
    
    def _load_config(self, config_path: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
            return config
        except Exception as e:
            print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _setup_logging(self):
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
        # ë¡œê±° ìƒì„±
        self.logger = logging.getLogger('TorchVideoProcessor')
        self.logger.setLevel(getattr(logging, self.config['logging']['level']))
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # í¬ë§¤í„° ì„¤ì •
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì˜µì…˜)
        if self.config['logging']['save_logs']:
            log_dir = "logs"
            os.makedirs(log_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_file = os.path.join(log_dir, f"torch_processing_{timestamp}.log")
            
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
            
            self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def _init_face_detector(self):
        """MTCNN ì–¼êµ´ íƒì§€ê¸° ì´ˆê¸°í™”"""
        mtcnn_config = self.config['mtcnn']
        
        self.face_detector = FaceDetector(
            image_size=mtcnn_config['image_size'],
            margin=mtcnn_config['margin'],
            prob_threshold=mtcnn_config['prob_threshold'],
            align_faces=mtcnn_config['align_faces']
        )
        
        self.logger.info(f"âœ… MTCNN ì´ˆê¸°í™” ì™„ë£Œ (ë°°ì¹˜ í¬ê¸°: {mtcnn_config['batch_size']})")
    
    def _load_classifier(self):
        """PyTorch ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ"""
        try:
            self.classifier = TorchFacialClassifier(self.config)
            self.logger.info("âœ… PyTorch ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_output_dirs(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        base_dir = self.config['output']['base_dir']
        os.makedirs(base_dir, exist_ok=True)
        
        if self.config['logging']['save_logs']:
            os.makedirs("logs", exist_ok=True)
    
    def _create_video_output_dir(self, video_path: str) -> str:
        """ì˜ìƒë³„ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        video_name = Path(video_path).stem
        timestamp = datetime.now().strftime("%Y%m%d")
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        safe_name = "".join(c for c in video_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        
        video_dir = os.path.join(
            self.config['output']['base_dir'],
            f"{timestamp}_{safe_name}"
        )
        
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±
        if self.config['output']['save_highlights']:
            os.makedirs(os.path.join(video_dir, "highlights"), exist_ok=True)
        
        if self.config['output']['save_timestamps']:
            os.makedirs(os.path.join(video_dir, "timestamps"), exist_ok=True)
        
        if self.config['output']['save_processing_log']:
            os.makedirs(os.path.join(video_dir, "logs"), exist_ok=True)
        
        return video_dir
    
    def _print_config_summary(self):
        """ì„¤ì • ìš”ì•½ ì¶œë ¥"""
        self.logger.info("ğŸ“‹ ì„¤ì • ìš”ì•½:")
        self.logger.info(f"   í”„ë ˆì„ ìŠ¤í‚µ: {self.config['video']['frame_skip']}í”„ë ˆì„ë§ˆë‹¤")
        self.logger.info(f"   MTCNN ë°°ì¹˜: {self.config['mtcnn']['batch_size']}")
        self.logger.info(f"   ë¶„ë¥˜ ë°°ì¹˜: {self.config['classifier']['batch_size']}")
        self.logger.info(f"   ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ: {self.config['classifier']['batch_timeout']}ì´ˆ")
        self.logger.info(f"   í í¬ê¸°: {self.config['performance']['max_queue_size']}")
        self.logger.info(f"   ë””ë°”ì´ìŠ¤: {self.config['classifier']['device']}")
    
    def process_video(self, video_path: str) -> Dict:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
        
        Args:
            video_path (str): ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        """
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        
        self.logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘: {os.path.basename(video_path)}")
        
        # ì˜ìƒë³„ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.video_output_dir = self._create_video_output_dir(video_path)
        self.logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.video_output_dir}")
        
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        video_info = self._get_video_info(video_path)
        self.logger.info(f"   ê¸¸ì´: {video_info['duration']:.1f}ì´ˆ, FPS: {video_info['fps']:.1f}")
        
        # ê²°ê³¼ ì €ì¥ìš© ë° í”Œë˜ê·¸ ì´ˆê¸°í™”
        self.angry_moments = []
        self.stats['processing_start_time'] = time.time()
        self.face_detection_done = False
        self.classification_done = False
        self.stop_flag = False
        
        # ìŠ¤ë ˆë“œ ì‹œì‘
        threads = []
        
        # 1. í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ
        frame_thread = threading.Thread(
            target=self._frame_reader_worker, 
            args=(video_path,)
        )
        threads.append(frame_thread)
        
        # 2. ì–¼êµ´ íƒì§€ ìŠ¤ë ˆë“œ
        face_thread = threading.Thread(target=self._face_detection_worker)
        threads.append(face_thread)
        
        # 3. ë°°ì¹˜ ë¶„ë¥˜ ìŠ¤ë ˆë“œ
        classify_thread = threading.Thread(target=self._batch_classification_worker)
        threads.append(classify_thread)
        
        # 4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ (ë°ëª¬ìœ¼ë¡œ ì„¤ì •)
        monitor_thread = threading.Thread(target=self._performance_monitor)
        monitor_thread.daemon = True
        threads.append(monitor_thread)
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì‹œì‘
        for thread in threads:
            thread.start()
        
        # í”„ë ˆì„ ì½ê¸° ì™„ë£Œ ëŒ€ê¸°
        frame_thread.join()
        self.logger.info("âœ… í”„ë ˆì„ ì½ê¸° ì™„ë£Œ")
        
        # ë‘ ì‘ì—… ëª¨ë‘ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        self.logger.info("â³ ì–¼êµ´ íƒì§€ ë° ë¶„ë¥˜ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
        while not (self.face_detection_done and self.classification_done):
            time.sleep(0.1)
        
        self.logger.info("âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì •
        self.stop_flag = True
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œë“¤ ì •ë¦¬
        face_thread.join(timeout=2)
        classify_thread.join(timeout=2)
        
        # ê²°ê³¼ ì €ì¥
        results = self._save_results(video_path, video_info)
        
        # ìµœì¢… í†µê³„ ì¶œë ¥
        self._print_final_stats()
        
        return results
    
    def _get_video_info(self, video_path: str) -> Dict:
        """ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ"""
        cap = cv2.VideoCapture(video_path)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps if fps > 0 else 0
        
        cap.release()
        
        return {
            'fps': fps,
            'frame_count': frame_count,
            'duration': duration
        }
    
    def _frame_reader_worker(self, video_path: str):
        """í”„ë ˆì„ ì½ê¸° ì›Œì»¤"""
        cap = cv2.VideoCapture(video_path)
        frame_skip = self.config['video']['frame_skip']
        frame_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # í”„ë ˆì„ ìŠ¤í‚µ
                if frame_count % frame_skip != 0:
                    frame_count += 1
                    continue
                
                # BGR to RGB ë³€í™˜
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°
                timestamp = frame_count / cap.get(cv2.CAP_PROP_FPS)
                
                # íì— ì¶”ê°€
                frame_data = {
                    'frame': frame_rgb,
                    'frame_number': frame_count,
                    'timestamp': timestamp
                }
                
                self.frame_queue.put(frame_data)
                frame_count += 1
                
        except Exception as e:
            self.logger.error(f"âŒ í”„ë ˆì„ ì½ê¸° ì˜¤ë¥˜: {e}")
        finally:
            cap.release()
            # ì¢…ë£Œ ì‹ í˜¸
            self.frame_queue.put(None)
            self.logger.info("ğŸ“¹ í”„ë ˆì„ ì½ê¸° ì›Œì»¤ ì¢…ë£Œ")
    
    def _face_detection_worker(self):
        """ì–¼êµ´ íƒì§€ ì›Œì»¤"""
        batch_size = self.config['mtcnn']['batch_size']
        frame_batch = []
        
        try:
            while True:
                frame_data = self.frame_queue.get()
                
                if frame_data is None:  # ì¢…ë£Œ ì‹ í˜¸
                    # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
                    if frame_batch:
                        self._process_face_batch(frame_batch)
                    self.face_queue.put(None)  # ë‹¤ìŒ ì›Œì»¤ì— ì¢…ë£Œ ì‹ í˜¸
                    break
                
                frame_batch.append(frame_data)
                
                # ë°°ì¹˜ê°€ ì°¼ìœ¼ë©´ ì²˜ë¦¬
                if len(frame_batch) >= batch_size:
                    self._process_face_batch(frame_batch)
                    frame_batch = []
                
                self.frame_queue.task_done()
                
        except Exception as e:
            self.logger.error(f"âŒ ì–¼êµ´ íƒì§€ ì˜¤ë¥˜: {e}")
        finally:
            self.face_detection_done = True
            self.logger.info("âœ… ì–¼êµ´ íƒì§€ ì™„ë£Œ")
    
    def _process_face_batch(self, frame_batch: List[Dict]):
        """í”„ë ˆì„ ë°°ì¹˜ì—ì„œ ì–¼êµ´ íƒì§€"""
        batch_start_time = time.time()
        faces_in_batch = 0
        
        for frame_data in frame_batch:
            try:
                # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                pil_image = Image.fromarray(frame_data['frame'])
                
                # ì–¼êµ´ íƒì§€
                face_images = self.face_detector.process_image(pil_image)
                
                if face_images:
                    for face_img in face_images:
                        face_data = {
                            'face_image': face_img,
                            'frame_number': frame_data['frame_number'],
                            'timestamp': frame_data['timestamp']
                        }
                        self.face_queue.put(face_data)
                        faces_in_batch += 1
                
                self.stats['frames_processed'] += 1
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ í”„ë ˆì„ {frame_data['frame_number']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        batch_time = time.time() - batch_start_time
        self.stats['faces_detected'] += faces_in_batch
        
        # ë°°ì¹˜ ë‹¨ìœ„ ë¡œê¹…
        if self.config['logging']['batch_summary']:
            self.logger.info(
                f"ì–¼êµ´ íƒì§€ ë°°ì¹˜: {len(frame_batch)}í”„ë ˆì„ â†’ {faces_in_batch}ê°œ ì–¼êµ´ "
                f"({batch_time:.2f}ì´ˆ)"
            )
    
    def _batch_classification_worker(self):
        """ë°°ì¹˜ ë¶„ë¥˜ ì›Œì»¤"""
        batch_size = self.config['classifier']['batch_size']
        timeout = self.config['classifier']['batch_timeout']
        
        face_batch = []
        last_batch_time = time.time()
        
        try:
            while True:
                try:
                    # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ì–¼êµ´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    remaining_timeout = max(0.1, timeout - (time.time() - last_batch_time))
                    face_data = self.face_queue.get(timeout=remaining_timeout)
                    
                    if face_data is None:  # ì¢…ë£Œ ì‹ í˜¸
                        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
                        if face_batch:
                            self._process_classification_batch(face_batch)
                        break
                    
                    face_batch.append(face_data)
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ì¡°ê±´ í™•ì¸
                    should_process = (
                        len(face_batch) >= batch_size or  # ë°°ì¹˜ê°€ ê°€ë“ ì°¸
                        (self.face_detection_done and len(face_batch) > 0) or  # íƒì§€ ì™„ë£Œ + ë‚¨ì€ ë°°ì¹˜
                        (time.time() - last_batch_time) >= timeout  # íƒ€ì„ì•„ì›ƒ
                    )
                    
                    if should_process:
                        self._process_classification_batch(face_batch)
                        face_batch = []
                        last_batch_time = time.time()
                    
                    self.face_queue.task_done()
                    
                except queue.Empty:
                    # íƒ€ì„ì•„ì›ƒ ë°œìƒ - í˜„ì¬ ë°°ì¹˜ ì²˜ë¦¬
                    if face_batch:
                        if self.config['logging']['batch_summary']:
                            self.logger.info(f"íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬: {len(face_batch)}ê°œ")
                        self._process_classification_batch(face_batch)
                        face_batch = []
                        last_batch_time = time.time()
                
        except Exception as e:
            self.logger.error(f"âŒ ë¶„ë¥˜ ì›Œì»¤ ì˜¤ë¥˜: {e}")
        finally:
            self.classification_done = True
            self.logger.info("âœ… ë¶„ë¥˜ ì²˜ë¦¬ ì™„ë£Œ")
    
    def _process_classification_batch(self, face_batch: List[Dict]):
        """ë¶„ë¥˜ ë°°ì¹˜ ì²˜ë¦¬"""
        if not face_batch:
            return
        
        try:
            # ì–¼êµ´ ì´ë¯¸ì§€ë“¤ ì¶”ì¶œ
            face_images = [face_data['face_image'] for face_data in face_batch]
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            batch_start_time = time.time()
            predictions = self.classifier.predict_batch(face_images)
            batch_time = time.time() - batch_start_time
            
            self.stats['batch_count'] += 1
            self.stats['total_inference_time'] += batch_time
            
            # ê²°ê³¼ ì²˜ë¦¬
            angry_count = 0
            for face_data, prediction in zip(face_batch, predictions):
                if prediction['is_angry']:
                    angry_moment = {
                        'timestamp': face_data['timestamp'],
                        'frame_number': face_data['frame_number'],
                        'confidence': prediction['confidence']
                    }
                    
                    self.angry_moments.append(angry_moment)
                    self.stats['angry_moments'] += 1
                    angry_count += 1
                    
                    # í‚¹ë°›ëŠ” í”„ë ˆì„ ì €ì¥ (ì˜µì…˜)
                    if self.config['output']['save_highlights']:
                        self._save_highlight_image(face_data, prediction['confidence'])
                    
                    if self.config['debug']['timing_detailed']:
                        timestamp_str = str(timedelta(seconds=int(face_data['timestamp'])))
                        self.logger.info(f"ğŸ˜¡ í‚¹ë°›ëŠ” ìˆœê°„! {timestamp_str} (ì‹ ë¢°ë„: {prediction['confidence']:.3f})")
            
        except Exception as e:
            self.logger.error(f"âš ï¸ ë°°ì¹˜ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
    
    def _save_highlight_image(self, face_data: Dict, confidence: float):
        """í‚¹ë°›ëŠ” ìˆœê°„ ì´ë¯¸ì§€ ì €ì¥"""
        try:
            timestamp_str = f"{int(face_data['timestamp']):05d}"
            filename = f"angry_{timestamp_str}_{confidence:.3f}.jpg"
            
            save_path = os.path.join(
                self.video_output_dir,
                "highlights",
                filename
            )
            
            face_data['face_image'].save(save_path)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í•˜ì´ë¼ì´íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _performance_monitor(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        interval = self.config['performance']['monitoring_interval']
        
        while not self.stop_flag:
            time.sleep(interval)
            
            if self.stats['processing_start_time'] is None:
                continue
            
            # í˜„ì¬ í†µê³„
            elapsed = time.time() - self.stats['processing_start_time']
            fps = self.stats['frames_processed'] / elapsed if elapsed > 0 else 0
            
            # í ìƒíƒœ
            frame_queue_size = self.frame_queue.qsize()
            face_queue_size = self.face_queue.qsize()
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_info = self.classifier.get_memory_usage()
            
            if self.config['logging']['performance_tracking']:
                avg_batch_time = (self.stats['total_inference_time'] / self.stats['batch_count'] 
                                 if self.stats['batch_count'] > 0 else 0)
                
                self.logger.info(
                    f"ğŸ“Š [{elapsed:.1f}s] "
                    f"í”„ë ˆì„: {self.stats['frames_processed']} ({fps:.1f} FPS), "
                    f"ì–¼êµ´: {self.stats['faces_detected']}, "
                    f"í‚¹ë°›ìŒ: {self.stats['angry_moments']}, "
                    f"í: {frame_queue_size}/{face_queue_size}, "
                    f"GPU: {memory_info['allocated']:.1f}GB, "
                    f"ë°°ì¹˜ í‰ê· : {avg_batch_time:.3f}ì´ˆ"
                )
        
        self.logger.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")
    
    def _save_results(self, video_path: str, video_info: Dict) -> Dict:
        """ê²°ê³¼ ì €ì¥"""
        results = {
            'video_path': video_path,
            'video_info': video_info,
            'processing_stats': self.stats.copy(),
            'angry_moments': self.angry_moments,
            'total_angry_moments': len(self.angry_moments),
            'config': self.config
        }
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ JSON ì €ì¥
        if self.config['output']['save_timestamps']:
            timestamp_file = os.path.join(
                self.video_output_dir,
                "timestamps",
                "angry_moments.json"
            )
            
            with open(timestamp_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {timestamp_file}")
        
        return results
    
    def _print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        elapsed = time.time() - self.stats['processing_start_time']
        fps = self.stats['frames_processed'] / elapsed if elapsed > 0 else 0
        avg_batch_time = (self.stats['total_inference_time'] / self.stats['batch_count'] 
                         if self.stats['batch_count'] > 0 else 0)
        
        self.logger.info("ğŸ¯ ì²˜ë¦¬ ì™„ë£Œ!")
        self.logger.info(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed:.1f}ì´ˆ")
        self.logger.info(f"   ì²˜ë¦¬ëœ í”„ë ˆì„: {self.stats['frames_processed']}ê°œ ({fps:.1f} FPS)")
        self.logger.info(f"   íƒì§€ëœ ì–¼êµ´: {self.stats['faces_detected']}ê°œ")
        self.logger.info(f"   í‚¹ë°›ëŠ” ìˆœê°„: {self.stats['angry_moments']}ê°œ")
        self.logger.info(f"   ë¶„ë¥˜ ë°°ì¹˜: {self.stats['batch_count']}íšŒ (í‰ê·  {avg_batch_time:.3f}ì´ˆ)")
        
        # GPU ë©”ëª¨ë¦¬ ìµœì¢… ì‚¬ìš©ëŸ‰
        memory_info = self.classifier.get_memory_usage()
        self.logger.info(f"   ìµœëŒ€ GPU ë©”ëª¨ë¦¬: {memory_info['max_allocated']:.1f}GB")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    import argparse
    
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='ì¹¨ì°©ë§¨ í‚¹ë°›ëŠ” ìˆœê°„ íƒì§€ (PyTorch)')
    parser.add_argument('filename', nargs='?', help='ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)')
    parser.add_argument('--dir', '--directory', help='ë¹„ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--config', default='config/config_torch.yaml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    try:
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        processor = TorchVideoProcessor(args.config)
        
        # ë¹„ë””ì˜¤ ê²½ë¡œ ê²°ì •
        if args.filename:
            # ëª…ë ¹ì¤„ì—ì„œ íŒŒì¼ëª… ì œê³µ
            video_dir = args.dir if args.dir else processor.config['video']['default_directory']
            video_path = os.path.join(video_dir, args.filename)
        else:
            # configì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©
            video_dir = processor.config['video']['default_directory']
            video_filename = processor.config['video']['default_filename']
            video_path = os.path.join(video_dir, video_filename)
        
        processor.logger.info(f"ğŸ¬ ì²˜ë¦¬í•  ì˜ìƒ: {video_path}")
        
        # ë¹„ë””ì˜¤ ì²˜ë¦¬
        results = processor.process_video(video_path)
        
        processor.logger.info("âœ… ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ê°•ì œ ì¢…ë£Œ
        print("ğŸ”š í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)


if __name__ == "__main__":
    main()
# EfficientNet-B0 PyTorch ì „ì´í•™ìŠµìœ¼ë¡œ ì–¼êµ´ í‘œì • ì´ì§„ë¶„ë¥˜
# ì•½ì˜¬ë¦¬ê¸° vs ë¹„ì•½ì˜¬ë¦¬ê¸° ë¶„ë¥˜

import os
import cv2
import numpy as np
import random
from PIL import Image
from tqdm import tqdm

# PyTorch ê´€ë ¨
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
import timm

# ë°ì´í„° ì¦ê°•
import albumentations as A
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# ëœë¤ ì‹œë“œ ê³ ì •
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
random.seed(SEED)

# CuDNN ê²°ì •ì  ë™ì‘ ì„¤ì •
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

print("=== ğŸš€ EfficientNet-B0 PyTorch ì „ì´í•™ìŠµ ì´ì§„ë¶„ë¥˜ ===")
print("ImageNet ì‚¬ì „í•™ìŠµ â†’ ì–¼êµ´ í‘œì • ë¶„ë¥˜ ì „ì´í•™ìŠµ")

# =================================
# GPU ì„¤ì • ë° ìµœì í™”
# =================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\n=== ğŸ”§ GPU ì„¤ì • ===")
print(f"Device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name()}")
    print(f"CUDA ë²„ì „: {torch.version.cuda}")
    print(f"ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    torch.cuda.empty_cache()
    print("âœ… CUDA ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# =================================
# PyTorch Dataset í´ë˜ìŠ¤
# =================================
class FacialExpressionDataset(Dataset):
    """ì–¼êµ´ í‘œì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ Dataset"""
    
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        
        # ì´ë¯¸ì§€ê°€ numpy arrayì¸ ê²½ìš° PILë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            # [0, 255] uint8ë¡œ ë³€í™˜
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            image = Image.fromarray(image)
        
        # ë°ì´í„° ì¦ê°• ì ìš©
        if self.transform:
            image = self.transform(image)
        
        return image, torch.tensor(label, dtype=torch.long)

# =================================
# EfficientNet-B0 ëª¨ë¸ ì •ì˜
# =================================
class EfficientNetClassifier(nn.Module):
    """EfficientNet-B0 ê¸°ë°˜ ì´ì§„ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self, num_classes=2, pretrained=True, dropout_rate=0.3):
        super(EfficientNetClassifier, self).__init__()
        
        # timmì—ì„œ EfficientNet-B0 ë¡œë“œ
        self.backbone = timm.create_model(
            'efficientnet_b0', 
            pretrained=pretrained,
            num_classes=0,  # ë¶„ë¥˜ í—¤ë“œ ì œê±°
            drop_rate=dropout_rate
        )
        
        # íŠ¹ì§• ì°¨ì› ì–»ê¸°
        self.feature_dim = self.backbone.num_features
        
        # ì»¤ìŠ¤í…€ ë¶„ë¥˜ í—¤ë“œ
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(self.feature_dim, num_classes)
        )
        
        print(f"âœ… EfficientNet-B0 ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print(f"   - ë°±ë³¸: timm.efficientnet_b0 (pretrained={pretrained})")
        print(f"   - íŠ¹ì§• ì°¨ì›: {self.feature_dim}")
        print(f"   - ë¶„ë¥˜ í—¤ë“œ: Dropout({dropout_rate}) â†’ Linear({self.feature_dim}, {num_classes})")
        
    def forward(self, x):
        # ë°±ë³¸ì„ í†µê³¼í•˜ì—¬ íŠ¹ì§• ì¶”ì¶œ
        features = self.backbone(x)
        # ë¶„ë¥˜ í—¤ë“œë¥¼ í†µê³¼
        outputs = self.classifier(features)
        return outputs
    
    def freeze_backbone(self):
        """ë°±ë³¸ ê°€ì¤‘ì¹˜ ë™ê²°"""
        for param in self.backbone.parameters():
            param.requires_grad = False
        print("ğŸ”’ ë°±ë³¸ ê°€ì¤‘ì¹˜ ë™ê²°ë¨")
    
    def unfreeze_backbone(self, layers_to_unfreeze=3):
        """ë°±ë³¸ ì¼ë¶€ ë ˆì´ì–´ í•´ì œ"""
        # ëª¨ë“  ë°±ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ì¼ë‹¨ ë™ê²°
        for param in self.backbone.parameters():
            param.requires_grad = False
        
        # ë§ˆì§€ë§‰ ëª‡ ê°œ ë ˆì´ì–´ë§Œ í•´ì œ
        backbone_children = list(self.backbone.children())
        
        # EfficientNetì˜ ë§ˆì§€ë§‰ ë¸”ë¡ë“¤ í•´ì œ
        if hasattr(self.backbone, 'blocks'):
            blocks = self.backbone.blocks
            total_blocks = len(blocks)
            unfreeze_from = max(0, total_blocks - layers_to_unfreeze)
            
            for i in range(unfreeze_from, total_blocks):
                for param in blocks[i].parameters():
                    param.requires_grad = True
            
            print(f"ğŸ”“ ë°±ë³¸ ë§ˆì§€ë§‰ {layers_to_unfreeze}ê°œ ë¸”ë¡ í•´ì œë¨ ({unfreeze_from}ë²ˆë¶€í„°)")
        
        # ë°°ì¹˜ ì •ê·œí™”ì™€ ë¶„ë¥˜ í—¤ë“œëŠ” í•­ìƒ í•™ìŠµ ê°€ëŠ¥
        for param in self.classifier.parameters():
            param.requires_grad = True

# =================================
# ëª¨ë¸ ìƒì„± ë° GPU ì´ë™
# =================================
print(f"\n=== ğŸ—ï¸ ëª¨ë¸ ìƒì„± ===")

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = EfficientNetClassifier(
    num_classes=2,
    pretrained=True,
    dropout_rate=0.3
)

# GPUë¡œ ì´ë™
model = model.to(device)

# ëª¨ë¸ ì •ë³´ ì¶œë ¥
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
print(f"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
print(f"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")
print(f"   - ë°±ë³¸ íŠ¹ì§• ì°¨ì›: {model.feature_dim}")

# =================================
# 1ë‹¨ê³„ í•™ìŠµ ì„¤ì • (ë°±ë³¸ ë™ê²°)
# =================================
print(f"\n=== ğŸ¯ 1ë‹¨ê³„ í•™ìŠµ ì„¤ì • (ë°±ë³¸ ë™ê²°) ===")

# ë°±ë³¸ ë™ê²°
model.freeze_backbone()

# 1ë‹¨ê³„ ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer_stage1 = optim.Adam(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=0.001,
    weight_decay=1e-4
)

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
scheduler_stage1 = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer_stage1,
    mode='min',
    factor=0.5,
    patience=3,
    min_lr=1e-7
)

# Mixed Precision ìŠ¤ì¼€ì¼ëŸ¬
scaler = GradScaler()

print("âœ… 1ë‹¨ê³„ í•™ìŠµ ì„¤ì • ì™„ë£Œ")
print(f"   - ì†ì‹¤í•¨ìˆ˜: CrossEntropyLoss")
print(f"   - ì˜µí‹°ë§ˆì´ì €: Adam (lr=0.001)")
print(f"   - ìŠ¤ì¼€ì¤„ëŸ¬: ReduceLROnPlateau")
print(f"   - Mixed Precision: í™œì„±í™”")

# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
trainable_params_stage1 = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"   - 1ë‹¨ê³„ í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params_stage1:,}")

# =================================
# ë°ì´í„° ë¡œë”© (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
# =================================
def load_images_robust(folder_path, label, max_images=None):
    """ë” ê°•ë ¥í•œ ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    images = []
    labels = []
    failed_files = []
    
    if not os.path.exists(folder_path):
        print(f"âŒ {folder_path} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return images, labels
    
    extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
    all_files = os.listdir(folder_path)
    image_files = [f for f in all_files if f.lower().endswith(extensions)]
    
    print(f"ğŸ“ {os.path.basename(folder_path)} í´ë”:")
    print(f"   ì „ì²´ íŒŒì¼: {len(all_files)}ê°œ")
    print(f"   ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    
    if max_images and len(image_files) > max_images:
        image_files = image_files[:max_images]
        print(f"   ì²˜ë¦¬ ëŒ€ìƒ: {len(image_files)}ê°œ (ì œí•œë¨)")
    
    for fname in tqdm(image_files, desc=f"Loading {os.path.basename(folder_path)}"):
        img_path = os.path.join(folder_path, fname)
        
        try:
            # ë°©ë²• 1: OpenCV
            img = cv2.imread(img_path)
            
            if img is None:
                # ë°©ë²• 2: PIL (í•œê¸€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
                pil_img = Image.open(img_path)
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            
            if img is None or img.shape[0] == 0 or img.shape[1] == 0:
                failed_files.append(fname)
                continue
                
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (224, 224))
            img = img.astype('float32') / 255.0  # [0,1] ì •ê·œí™”
            
            images.append(img)
            labels.append(label)
            
        except Exception as e:
            failed_files.append(f"{fname}: {str(e)}")
            continue
    
    print(f"   âœ… ì„±ê³µ: {len(images)}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
    
    if failed_files:
        print(f"   ì‹¤íŒ¨ íŒŒì¼ë“¤: {failed_files[:3]}...")
    
    return images, labels

# ë°ì´í„° ê²½ë¡œ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
base_path = 'data/processed'
teasing_path = os.path.join(base_path, 'teasing')
non_teasing_path = os.path.join(base_path, 'non_teasing')

print("\n=== ğŸ“ ë°ì´í„° ë¡œë”© ===")
# ë¹„ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 0)
X_non_teasing, y_non_teasing = load_images_robust(non_teasing_path, 0)

# ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 1)
X_teasing, y_teasing = load_images_robust(teasing_path, 1)

# ë°ì´í„° í•©ì¹˜ê¸°
X = X_non_teasing + X_teasing
y = y_non_teasing + y_teasing

print(f"ë¡œë”© ì™„ë£Œ:")
print(f"  ë¹„ì•½ì˜¬ë¦¬ê¸°: {len(X_non_teasing)}ê°œ")
print(f"  ì•½ì˜¬ë¦¬ê¸°: {len(X_teasing)}ê°œ")
print(f"  ì´ ì´ë¯¸ì§€: {len(X)}ê°œ")

if len(X) == 0:
    print("âŒ ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# =================================
# ì›ë³¸ ë°ì´í„° ë¶„í•  (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
# =================================
print(f"\n=== âœ‚ï¸ ì›ë³¸ ë°ì´í„° ë¶„í•  ===")

X_raw = np.array(X)
y_raw = np.array(y)

print(f"ì›ë³¸ ë°ì´í„°: {X_raw.shape}")
print(f"ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_raw)}")

# ì›ë³¸ ë°ì´í„°ë¥¼ ë¨¼ì € ë¶„í• 
X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(
    X_raw, y_raw, test_size=0.2, random_state=SEED, stratify=y_raw
)

print(f"ì›ë³¸ í›ˆë ¨ ë°ì´í„°: {X_train_raw.shape}")
print(f"ì›ë³¸ ê²€ì¦ ë°ì´í„°: {X_val_raw.shape}")
print(f"ì›ë³¸ í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train_raw)}")
print(f"ì›ë³¸ ê²€ì¦ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_val_raw)}")

# =================================
# PyTorch Transform ì •ì˜
# =================================
from torchvision import transforms

# í›ˆë ¨ìš© Transform (ë°ì´í„° ì¦ê°•)
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),
    transforms.RandomRotation(degrees=5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”
])

# ê²€ì¦ìš© Transform (ì¦ê°• ì—†ìŒ)
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print(f"\n=== ğŸ”„ Transform ì„¤ì • ===")
print("âœ… í›ˆë ¨ìš©: Resize + RandomFlip + ColorJitter + ì •ê·œí™”")
print("âœ… ê²€ì¦ìš©: Resize + ì •ê·œí™”ë§Œ")

# =================================
# ë°ì´í„° ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ)
# =================================
def augment_data_pytorch(X_array, y_array, target_per_class=250):
    """PyTorchìš© ë°ì´í„° ì¦ê°• í•¨ìˆ˜"""
    
    class_0_indices = np.where(y_array == 0)[0]
    class_1_indices = np.where(y_array == 1)[0]
    
    class_0_data = [X_array[i] for i in class_0_indices]
    class_1_data = [X_array[i] for i in class_1_indices]
    
    print(f"\n=== ğŸ”„ í›ˆë ¨ ë°ì´í„° ì¦ê°• ===")
    print(f"ì¦ê°• ì „: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(class_0_data)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(class_1_data)}ê°œ")
    
    # Albumentations ì‚¬ìš© (ê¸°ì¡´ê³¼ ë™ì¼)
    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.5),
        A.GaussNoise(var_limit=(10, 50), p=0.3),
    ])

    final_class_0 = class_0_data.copy()
    final_class_1 = class_1_data.copy()

    # ë¹„ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_0_data) < target_per_class:
        need_count = target_per_class - len(class_0_data)
        print(f"ë¹„ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_0_data[i % len(class_0_data)]
            # uint8ë¡œ ë³€í™˜
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_0.append(aug_img)

    # ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_1_data) < target_per_class:
        need_count = target_per_class - len(class_1_data)
        print(f"ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_1_data[i % len(class_1_data)]
            # uint8ë¡œ ë³€í™˜
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_1.append(aug_img)
    
    # ìµœì¢… ë°ì´í„°
    final_X = final_class_0 + final_class_1
    final_y = [0] * len(final_class_0) + [1] * len(final_class_1)
    
    print(f"ì¦ê°• í›„: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(final_class_0)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(final_class_1)}ê°œ")
    print(f"ì´ í›ˆë ¨ ë°ì´í„°: {len(final_X)}ê°œ")
    
    return final_X, final_y

# í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°• (ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ìœ ì§€!)
X_train_aug, y_train_aug = augment_data_pytorch(X_train_raw, y_train_raw, target_per_class=250)

# =================================
# Dataset ë° DataLoader ìƒì„±
# =================================
print(f"\n=== ğŸ“¦ Dataset ë° DataLoader ìƒì„± ===")

# Dataset ìƒì„±
train_dataset = FacialExpressionDataset(X_train_aug, y_train_aug, transform=train_transform)
val_dataset = FacialExpressionDataset(X_val_raw, y_val_raw, transform=val_transform)

print(f"âœ… Dataset ìƒì„± ì™„ë£Œ")
print(f"   - í›ˆë ¨ Dataset: {len(train_dataset)}ê°œ")
print(f"   - ê²€ì¦ Dataset: {len(val_dataset)}ê°œ")

# DataLoader ìƒì„± (Windows í˜¸í™˜)
batch_size = 32
num_workers = 0  # Windowsì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ ë°©ì§€

train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers,
    pin_memory=True,  # GPU ì „ì†¡ ìµœì í™”
    drop_last=True    # ë§ˆì§€ë§‰ ë°°ì¹˜ í¬ê¸° í†µì¼
)

val_loader = DataLoader(
    val_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True
)

print(f"âœ… DataLoader ìƒì„± ì™„ë£Œ")
print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
print(f"   - Worker ìˆ˜: {num_workers}")
print(f"   - í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
print(f"   - ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
print(f"   - GPU ë©”ëª¨ë¦¬ ìµœì í™”: pin_memory=True")

# =================================
# í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜
# =================================
def train_epoch(model, train_loader, criterion, optimizer, scaler, device):
    """í•œ ì—í¬í¬ í›ˆë ¨"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(train_loader, desc="Training")
    for batch_idx, (images, labels) in enumerate(pbar):
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        # Mixed Precision Training
        with autocast():
            outputs = model(images)
            loss = criterion(outputs, labels)
        
        # Backward pass
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        # í†µê³„ ê³„ì‚°
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        pbar.set_postfix({
            'Loss': f'{running_loss/(batch_idx+1):.4f}',
            'Acc': f'{100.*correct/total:.2f}%'
        })
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

def validate_epoch(model, val_loader, criterion, device):
    """í•œ ì—í¬í¬ ê²€ì¦"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        pbar = tqdm(val_loader, desc="Validation")
        for batch_idx, (images, labels) in enumerate(pbar):
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # ì˜ˆì¸¡ê°’ ì €ì¥ (ë‚˜ì¤‘ì— ë¶„ì„ìš©)
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            pbar.set_postfix({
                'Loss': f'{running_loss/(batch_idx+1):.4f}',
                'Acc': f'{100.*correct/total:.2f}%'
            })
    
    epoch_loss = running_loss / len(val_loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc, all_predictions, all_labels

# =================================
# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
# =================================
import os
from datetime import datetime

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ
results_base = "results/pytorch_efficientnet"
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# ë””ë ‰í† ë¦¬ ìƒì„±
dirs_to_create = [
    f"{results_base}/models",
    f"{results_base}/plots", 
    f"{results_base}/metrics",
    f"{results_base}/logs"
]

for dir_path in dirs_to_create:
    os.makedirs(dir_path, exist_ok=True)

print(f"\n=== ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± ===")
print(f"ê¸°ë³¸ ê²½ë¡œ: {results_base}")
for dir_path in dirs_to_create:
    print(f"âœ… {dir_path}")

# =================================
# 1ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ
# =================================
print(f"\n=== ğŸš€ 1ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ ===")

# 1ë‹¨ê³„ ì„¤ì •
stage1_epochs = 15
best_val_loss = float('inf')
patience_counter = 0
patience = 5

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •
class_counts = np.bincount(y_train_aug)
class_weights = torch.tensor([1.0, 2.0], dtype=torch.float).to(device)  # teasing í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€
criterion_weighted = nn.CrossEntropyLoss(weight=class_weights)

print(f"1ë‹¨ê³„ í•™ìŠµ ì‹œì‘:")
print(f"  - ì—í¬í¬: {stage1_epochs}")
print(f"  - ë°±ë³¸: ì™„ì „ ë™ê²°")
print(f"  - í•™ìŠµë¥ : {optimizer_stage1.param_groups[0]['lr']}")
print(f"  - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}")
print(f"  - ì¡°ê¸° ì¢…ë£Œ: patience={patience}")

# 1ë‹¨ê³„ í•™ìŠµ ê¸°ë¡
stage1_history = {
    'train_loss': [], 'train_acc': [],
    'val_loss': [], 'val_acc': []
}

for epoch in range(stage1_epochs):
    print(f"\nğŸ“Š Epoch {epoch+1}/{stage1_epochs}")
    
    # í›ˆë ¨
    train_loss, train_acc = train_epoch(
        model, train_loader, criterion_weighted, optimizer_stage1, scaler, device
    )
    
    # ê²€ì¦
    val_loss, val_acc, val_predictions, val_labels = validate_epoch(
        model, val_loader, criterion_weighted, device
    )
    
    # ê¸°ë¡ ì €ì¥
    stage1_history['train_loss'].append(train_loss)
    stage1_history['train_acc'].append(train_acc)
    stage1_history['val_loss'].append(val_loss)
    stage1_history['val_acc'].append(val_acc)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
    scheduler_stage1.step(val_loss)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ’¯ Results - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
    print(f"ğŸ’¯ Results - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
    print(f"ğŸ“š LR: {optimizer_stage1.param_groups[0]['lr']:.6f}")
    
    # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        # ìµœê³  ëª¨ë¸ ì €ì¥ (ì •í™•í•œ ê²½ë¡œë¡œ)
        stage1_model_path = f"{results_base}/models/best_model_stage1_{timestamp}.pth"
        torch.save(model.state_dict(), stage1_model_path)
        print(f"ğŸ’¾ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨: {stage1_model_path}")
    else:
        patience_counter += 1
        print(f"â° Patience: {patience_counter}/{patience}")
        
        if patience_counter >= patience:
            print("ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ!")
            break

# ìµœê³  ëª¨ë¸ ë¡œë“œ
stage1_model_path = f"{results_base}/models/best_model_stage1_{timestamp}.pth"
model.load_state_dict(torch.load(stage1_model_path))
print(f"\nâœ… 1ë‹¨ê³„ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")

# =================================
# 2ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ì¼ë¶€ í•´ì œ + ë¯¸ì„¸ì¡°ì •
# =================================
print(f"\n=== ğŸ”¬ 2ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ì¼ë¶€ í•´ì œ + ë¯¸ì„¸ì¡°ì • ===")

# ë°±ë³¸ ì¼ë¶€ í•´ì œ
model.unfreeze_backbone(layers_to_unfreeze=3)

# 2ë‹¨ê³„ ì˜µí‹°ë§ˆì´ì € (ë” ì‘ì€ í•™ìŠµë¥ )
optimizer_stage2 = optim.Adam(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=0.0001,  # 10ë°° ì‘ì€ í•™ìŠµë¥ 
    weight_decay=1e-4
)

# 2ë‹¨ê³„ ìŠ¤ì¼€ì¤„ëŸ¬
scheduler_stage2 = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer_stage2,
    mode='min',
    factor=0.3,
    patience=3,
    min_lr=1e-8
)

# 2ë‹¨ê³„ ì„¤ì •
stage2_epochs = 20
best_val_loss_stage2 = float('inf')
patience_counter_stage2 = 0
patience_stage2 = 7

# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
trainable_params_stage2 = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"2ë‹¨ê³„ í•™ìŠµ ì‹œì‘:")
print(f"  - ì—í¬í¬: {stage2_epochs}")
print(f"  - í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params_stage2:,}")
print(f"  - í•™ìŠµë¥ : {optimizer_stage2.param_groups[0]['lr']}")
print(f"  - ì¡°ê¸° ì¢…ë£Œ: patience={patience_stage2}")

# 2ë‹¨ê³„ í•™ìŠµ ê¸°ë¡
stage2_history = {
    'train_loss': [], 'train_acc': [],
    'val_loss': [], 'val_acc': []
}

for epoch in range(stage2_epochs):
    print(f"\nğŸ“Š Stage2 Epoch {epoch+1}/{stage2_epochs}")
    
    # í›ˆë ¨
    train_loss, train_acc = train_epoch(
        model, train_loader, criterion_weighted, optimizer_stage2, scaler, device
    )
    
    # ê²€ì¦
    val_loss, val_acc, val_predictions, val_labels = validate_epoch(
        model, val_loader, criterion_weighted, device
    )
    
    # ê¸°ë¡ ì €ì¥
    stage2_history['train_loss'].append(train_loss)
    stage2_history['train_acc'].append(train_acc)
    stage2_history['val_loss'].append(val_loss)
    stage2_history['val_acc'].append(val_acc)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
    scheduler_stage2.step(val_loss)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ’¯ Results - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
    print(f"ğŸ’¯ Results - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
    print(f"ğŸ“š LR: {optimizer_stage2.param_groups[0]['lr']:.6f}")
    
    # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
    if val_loss < best_val_loss_stage2:
        best_val_loss_stage2 = val_loss
        patience_counter_stage2 = 0
        # ìµœê³  ëª¨ë¸ ì €ì¥ (ì •í™•í•œ ê²½ë¡œë¡œ)
        stage2_model_path = f"{results_base}/models/best_model_stage2_{timestamp}.pth"
        torch.save(model.state_dict(), stage2_model_path)
        print(f"ğŸ’¾ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨: {stage2_model_path}")
    else:
        patience_counter_stage2 += 1
        print(f"â° Patience: {patience_counter_stage2}/{patience_stage2}")
        
        if patience_counter_stage2 >= patience_stage2:
            print("ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ!")
            break

# ìµœê³  ëª¨ë¸ ë¡œë“œ
stage2_model_path = f"{results_base}/models/best_model_stage2_{timestamp}.pth"
model.load_state_dict(torch.load(stage2_model_path))
print(f"\nâœ… 2ë‹¨ê³„ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss_stage2:.4f}")

# =================================
# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
# =================================
import os
from datetime import datetime

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ
results_base = "results/pytorch_efficientnet"
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# ë””ë ‰í† ë¦¬ ìƒì„±
dirs_to_create = [
    f"{results_base}/models",
    f"{results_base}/plots", 
    f"{results_base}/metrics",
    f"{results_base}/logs"
]

for dir_path in dirs_to_create:
    os.makedirs(dir_path, exist_ok=True)

print(f"\n=== ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± ===")
print(f"ê¸°ë³¸ ê²½ë¡œ: {results_base}")
for dir_path in dirs_to_create:
    print(f"âœ… {dir_path}")

# =================================
# ìµœì¢… ì„±ëŠ¥ í‰ê°€
# =================================
print(f"\n=== ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ===")

# ìµœì¢… ê²€ì¦ ìˆ˜í–‰
model.eval()
final_val_loss, final_val_acc, final_predictions, final_labels = validate_epoch(
    model, val_loader, criterion_weighted, device
)

print(f"ìµœì¢… ê²€ì¦ ê²°ê³¼:")
print(f"  - ê²€ì¦ ì •í™•ë„: {final_val_acc:.2f}%")
print(f"  - ê²€ì¦ ì†ì‹¤: {final_val_loss:.4f}")

# F1 Score ê³„ì‚°
from sklearn.metrics import f1_score, precision_score, recall_score

f1 = f1_score(final_labels, final_predictions)
precision = precision_score(final_labels, final_predictions)
recall = recall_score(final_labels, final_predictions)

print(f"  - F1 Score: {f1:.4f}")
print(f"  - Precision: {precision:.4f}")
print(f"  - Recall: {recall:.4f}")

# ë¶„ë¥˜ ë³´ê³ ì„œ
classes = ['non_teasing', 'teasing']
print(f"\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(final_labels, final_predictions, target_names=classes))

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(final_labels, final_predictions)
print(f"\ní˜¼ë™ í–‰ë ¬:")
print(cm)

# =================================
# ê²°ê³¼ ì‹œê°í™”
# =================================
print(f"\n=== ğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ===")

# ì „ì²´ í•™ìŠµ ê¸°ë¡ í•©ì¹˜ê¸°
total_epochs_stage1 = len(stage1_history['train_loss'])
total_epochs_stage2 = len(stage2_history['train_loss'])

# ì—°ì†ëœ ì—í¬í¬ë¡œ ë³€í™˜
all_train_loss = stage1_history['train_loss'] + stage2_history['train_loss']
all_train_acc = stage1_history['train_acc'] + stage2_history['train_acc']
all_val_loss = stage1_history['val_loss'] + stage2_history['val_loss']
all_val_acc = stage1_history['val_acc'] + stage2_history['val_acc']

# ì—í¬í¬ ë²”ìœ„
epochs_stage1 = list(range(1, total_epochs_stage1 + 1))
epochs_stage2 = list(range(total_epochs_stage1 + 1, total_epochs_stage1 + total_epochs_stage2 + 1))
all_epochs = epochs_stage1 + epochs_stage2

# ì‹œê°í™”
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('EfficientNet-B0 PyTorch 2-Stage Training Results', fontsize=16)

# 1. ì •í™•ë„ ê·¸ë˜í”„
axes[0,0].plot(epochs_stage1, stage1_history['train_acc'], 'b-', label='Stage 1 Training', linewidth=2)
axes[0,0].plot(epochs_stage1, stage1_history['val_acc'], 'b--', label='Stage 1 Validation', linewidth=2)
axes[0,0].plot(epochs_stage2, stage2_history['train_acc'], 'g-', label='Stage 2 Training', linewidth=2)
axes[0,0].plot(epochs_stage2, stage2_history['val_acc'], 'g--', label='Stage 2 Validation', linewidth=2)
axes[0,0].axhline(y=50, color='gray', linestyle=':', alpha=0.7, label='Random Baseline')
axes[0,0].axvline(x=total_epochs_stage1, color='red', linestyle=':', alpha=0.7, label='Stage Transition')
axes[0,0].set_title('Model Accuracy (2-Stage Training)')
axes[0,0].set_xlabel('Epoch')
axes[0,0].set_ylabel('Accuracy (%)')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# 2. ì†ì‹¤ ê·¸ë˜í”„
axes[0,1].plot(epochs_stage1, stage1_history['train_loss'], 'b-', label='Stage 1 Training', linewidth=2)
axes[0,1].plot(epochs_stage1, stage1_history['val_loss'], 'b--', label='Stage 1 Validation', linewidth=2)
axes[0,1].plot(epochs_stage2, stage2_history['train_loss'], 'g-', label='Stage 2 Training', linewidth=2)
axes[0,1].plot(epochs_stage2, stage2_history['val_loss'], 'g--', label='Stage 2 Validation', linewidth=2)
axes[0,1].axvline(x=total_epochs_stage1, color='red', linestyle=':', alpha=0.7, label='Stage Transition')
axes[0,1].set_title('Model Loss (2-Stage Training)')
axes[0,1].set_xlabel('Epoch')
axes[0,1].set_ylabel('Loss')
axes[0,1].legend()
axes[0,1].grid(True, alpha=0.3)

# 3. í˜¼ë™ í–‰ë ¬ íˆíŠ¸ë§µ
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
           xticklabels=classes, yticklabels=classes, ax=axes[1,0])
axes[1,0].set_title('Confusion Matrix')
axes[1,0].set_xlabel('Predicted')
axes[1,0].set_ylabel('Actual')

# 4. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ (ë§ˆì§€ë§‰ ë°°ì¹˜ ê¸°ì¤€)
model.eval()
with torch.no_grad():
    # ìƒ˜í”Œ ë°°ì¹˜ë¡œ í™•ë¥  ë¶„í¬ í™•ì¸
    sample_images, sample_labels = next(iter(val_loader))
    sample_images, sample_labels = sample_images.to(device), sample_labels.to(device)
    sample_outputs = model(sample_images)
    sample_probs = torch.softmax(sample_outputs, dim=1)[:, 1].cpu().numpy()  # teasing í´ë˜ìŠ¤ í™•ë¥ 
    sample_labels_cpu = sample_labels.cpu().numpy()

axes[1,1].hist(sample_probs[sample_labels_cpu==0], alpha=0.5, label='non_teasing', bins=20, color='blue')
axes[1,1].hist(sample_probs[sample_labels_cpu==1], alpha=0.5, label='teasing', bins=20, color='orange')
axes[1,1].axvline(x=0.5, color='red', linestyle='--', label='Decision Threshold')
axes[1,1].set_title('Prediction Probability Distribution (Sample)')
axes[1,1].set_xlabel('Predicted Probability (Teasing Class)')
axes[1,1].set_ylabel('Count')
axes[1,1].legend()
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()

# ê·¸ë˜í”„ ì €ì¥
plot_path = f"{results_base}/plots/training_results_{timestamp}.png"
plt.savefig(plot_path, dpi=300, bbox_inches='tight')
print(f"ğŸ“ˆ í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: {plot_path}")

plt.show()

# =================================
# ì„±ëŠ¥ ê°œì„  ë¶„ì„
# =================================
print(f"\n=== ğŸ¯ ì„±ëŠ¥ ê°œì„  ë¶„ì„ ===")

# ê¸°ì¤€ì„ ê³¼ ë¹„êµ (ê¸°ì¡´ TensorFlow ëª¨ë¸ ê¸°ì¤€)
baseline_accuracy = 77.5  # ê¸°ì¡´ CNN ì„±ëŠ¥
improvement = final_val_acc - baseline_accuracy
improvement_percent = (improvement / baseline_accuracy) * 100

print(f"âœ… PyTorch EfficientNet-B0 ì „ì´í•™ìŠµ ê²°ê³¼:")
print(f"   - ê¸°ì¡´ TensorFlow CNN: {baseline_accuracy}%")
print(f"   - PyTorch EfficientNet: {final_val_acc:.1f}%")
print(f"   - ê°œì„ í­: {improvement:+.1f}% ({improvement_percent:+.1f}%)")
print(f"   - F1 Score: {f1:.4f}")
print(f"   - ì´ í•™ìŠµ ì—í¬í¬: {total_epochs_stage1 + total_epochs_stage2}íšŒ")

# ì„±ëŠ¥ í‰ê°€
if final_val_acc > 85:
    print(f"ğŸ‰ ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±! ì „ì´í•™ìŠµì´ ë§¤ìš° íš¨ê³¼ì ")
elif final_val_acc > 82:
    print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! ì „ì´í•™ìŠµì´ ë§¤ìš° íš¨ê³¼ì ") 
elif final_val_acc > 80:
    print(f"ğŸ‘ ëª©í‘œ ê·¼ì ‘! ì „ì´í•™ìŠµ íš¨ê³¼ í™•ì¸")
elif final_val_acc > baseline_accuracy:
    print(f"âœ¨ ì„±ëŠ¥ í–¥ìƒ! ì „ì´í•™ìŠµ ë„ì›€ë¨")
else:
    print(f"ğŸ¤” ì„±ëŠ¥ ì •ì²´. ì¶”ê°€ ì¡°ì • í•„ìš”")

# =================================
# ê²°ê³¼ ì €ì¥
# =================================
print(f"\n=== ğŸ’¾ ê²°ê³¼ ì €ì¥ ===")

# ìµœì¢… ëª¨ë¸ ì €ì¥
final_model_path = f"{results_base}/models/final_model_{timestamp}.pth"
torch.save(model.state_dict(), final_model_path)
print(f"ğŸ¤– ìµœì¢… ëª¨ë¸ ì €ì¥: {final_model_path}")

# í•™ìŠµ ê¸°ë¡ ì €ì¥
import json
training_log = {
    'timestamp': timestamp,
    'model_config': {
        'backbone': 'efficientnet_b0',
        'num_classes': 2,
        'dropout_rate': 0.3
    },
    'training_config': {
        'stage1_epochs': total_epochs_stage1,
        'stage2_epochs': total_epochs_stage2,
        'batch_size': batch_size,
        'num_workers': num_workers,
        'mixed_precision': True
    },
    'final_metrics': {
        'val_accuracy': float(final_val_acc),
        'val_loss': float(final_val_loss),
        'f1_score': float(f1),
        'precision': float(precision),
        'recall': float(recall)
    },
    'stage1_history': {
        'train_loss': [float(x) for x in stage1_history['train_loss']],
        'train_acc': [float(x) for x in stage1_history['train_acc']],
        'val_loss': [float(x) for x in stage1_history['val_loss']],
        'val_acc': [float(x) for x in stage1_history['val_acc']]
    },
    'stage2_history': {
        'train_loss': [float(x) for x in stage2_history['train_loss']],
        'train_acc': [float(x) for x in stage2_history['train_acc']],
        'val_loss': [float(x) for x in stage2_history['val_loss']],
        'val_acc': [float(x) for x in stage2_history['val_acc']]
    }
}

log_path = f"{results_base}/logs/training_log_{timestamp}.json"
with open(log_path, 'w', encoding='utf-8') as f:
    json.dump(training_log, f, indent=2, ensure_ascii=False)
print(f"ğŸ“Š í•™ìŠµ ë¡œê·¸ ì €ì¥: {log_path}")

# ì„±ëŠ¥ ì§€í‘œ ì €ì¥
metrics_text = f"""PyTorch EfficientNet-B0 ì „ì´í•™ìŠµ ê²°ê³¼
================================================
ì‹¤í–‰ ì‹œê°„: {timestamp}

ìµœì¢… ì„±ëŠ¥:
- ê²€ì¦ ì •í™•ë„: {final_val_acc:.2f}%
- ê²€ì¦ ì†ì‹¤: {final_val_loss:.4f}
- F1 Score: {f1:.4f}
- Precision: {precision:.4f}
- Recall: {recall:.4f}

í•™ìŠµ ì„¤ì •:
- 1ë‹¨ê³„ ì—í¬í¬: {total_epochs_stage1}
- 2ë‹¨ê³„ ì—í¬í¬: {total_epochs_stage2}
- ì´ ì—í¬í¬: {total_epochs_stage1 + total_epochs_stage2}
- ë°°ì¹˜ í¬ê¸°: {batch_size}
- Mixed Precision: í™œì„±í™”

ê¸°ì¡´ ëŒ€ë¹„ ê°œì„ :
- ê¸°ì¡´ TensorFlow CNN: {baseline_accuracy}%
- PyTorch EfficientNet: {final_val_acc:.1f}%
- ê°œì„ í­: {improvement:+.1f}% ({improvement_percent:+.1f}%)

í˜¼ë™ í–‰ë ¬:
{cm}

ë¶„ë¥˜ ë³´ê³ ì„œ:
{classification_report(final_labels, final_predictions, target_names=classes)}
"""

metrics_path = f"{results_base}/metrics/performance_summary_{timestamp}.txt"
with open(metrics_path, 'w', encoding='utf-8') as f:
    f.write(metrics_text)
print(f"ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½ ì €ì¥: {metrics_path}")

print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:")
if final_val_acc < 80:
    print(f"   - ë°ì´í„° ìˆ˜ì§‘ í™•ëŒ€")
    print(f"   - VGGFace2 ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‹œë„ (ë…¼ë¬¸ ê¸°ë²•)")
    print(f"   - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    print(f"   - ê°•ê±´í•œ ìµœì í™”(Robust Optimization) ì ìš©")
else:
    print(f"   - ëª¨ë¸ ì•™ìƒë¸” ì‹œë„")
    print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… ê²€ì¦")
    print(f"   - ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ê³ ë ¤")
    print(f"   - ë…¼ë¬¸ ê¸°ë²•(VGGFace2 + ê°•ê±´í•œ ìµœì í™”) ì ìš©ìœ¼ë¡œ ì¶”ê°€ í–¥ìƒ")

print(f"\nğŸš€ PyTorch EfficientNet-B0 ì „ì´í•™ìŠµ ì™„ë£Œ!")
print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ê°€ {results_base}/ ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
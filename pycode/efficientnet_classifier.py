# EfficientNet-B0 ì „ì´í•™ìŠµìœ¼ë¡œ ì–¼êµ´ í‘œì • ì´ì§„ë¶„ë¥˜
# ì•½ì˜¬ë¦¬ê¸° vs ë¹„ì•½ì˜¬ë¦¬ê¸° ë¶„ë¥˜

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input

import albumentations as A
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import matplotlib.pyplot as plt
from tqdm import tqdm
import random

# ëœë¤ ì‹œë“œ ê³ ì •
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)

print("=== ğŸš€ EfficientNet-B0 ì „ì´í•™ìŠµ ì´ì§„ë¶„ë¥˜ ===")
print("ImageNet ì‚¬ì „í•™ìŠµ â†’ ì–¼êµ´ í‘œì • ë¶„ë¥˜ ì „ì´í•™ìŠµ")

# =================================
# 1. ë°ì´í„° ë¡œë”©
# =================================
def load_images_robust(folder_path, label, max_images=None):
    """ë” ê°•ë ¥í•œ ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜"""
    from PIL import Image
    images = []
    labels = []
    failed_files = []
    
    if not os.path.exists(folder_path):
        print(f"âŒ {folder_path} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return images, labels
    
    extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
    all_files = os.listdir(folder_path)
    image_files = [f for f in all_files if f.lower().endswith(extensions)]
    
    print(f"ğŸ“ {os.path.basename(folder_path)} í´ë”:")
    print(f"   ì „ì²´ íŒŒì¼: {len(all_files)}ê°œ")
    print(f"   ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    
    if max_images and len(image_files) > max_images:
        image_files = image_files[:max_images]
        print(f"   ì²˜ë¦¬ ëŒ€ìƒ: {len(image_files)}ê°œ (ì œí•œë¨)")
    
    for fname in tqdm(image_files, desc=f"Loading {os.path.basename(folder_path)}"):
        img_path = os.path.join(folder_path, fname)
        
        try:
            # ë°©ë²• 1: OpenCV
            img = cv2.imread(img_path)
            
            if img is None:
                # ë°©ë²• 2: PIL (í•œê¸€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
                pil_img = Image.open(img_path)
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            
            if img is None or img.shape[0] == 0 or img.shape[1] == 0:
                failed_files.append(fname)
                continue
                
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (224, 224))
            img = img.astype('float32') # [0,255] ìœ ì§€
            
            images.append(img)
            labels.append(label)
            
        except Exception as e:
            failed_files.append(f"{fname}: {str(e)}")
            continue
    
    print(f"   âœ… ì„±ê³µ: {len(images)}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {len(failed_files)}ê°œ")
    
    if failed_files:
        print(f"   ì‹¤íŒ¨ íŒŒì¼ë“¤: {failed_files[:3]}...")
    
    return images, labels

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
base_path = r'D:\my_projects\calmman-facial-classification\data\processed'
teasing_path = os.path.join(base_path, 'teasing')
non_teasing_path = os.path.join(base_path, 'non_teasing')

print("\n=== ğŸ“ ë°ì´í„° ë¡œë”© ===")
# ë¹„ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 0)
X_non_teasing, y_non_teasing = load_images_robust(non_teasing_path, 0)

# ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ ë¡œë“œ (ë¼ë²¨: 1)
X_teasing, y_teasing = load_images_robust(teasing_path, 1)

# ë°ì´í„° í•©ì¹˜ê¸°
X = X_non_teasing + X_teasing
y = y_non_teasing + y_teasing

print(f"ë¡œë”© ì™„ë£Œ:")
print(f"  ë¹„ì•½ì˜¬ë¦¬ê¸°: {len(X_non_teasing)}ê°œ")
print(f"  ì•½ì˜¬ë¦¬ê¸°: {len(X_teasing)}ê°œ")
print(f"  ì´ ì´ë¯¸ì§€: {len(X)}ê°œ")

if len(X) == 0:
    print("âŒ ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# =================================
# 2. ì›ë³¸ ë°ì´í„° ë¶„í•  (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
# =================================
print(f"\n=== âœ‚ï¸ ì›ë³¸ ë°ì´í„° ë¶„í•  ===")

X_raw = np.array(X)
y_raw = np.array(y)

print(f"ì›ë³¸ ë°ì´í„°: {X_raw.shape}")
print(f"ì›ë³¸ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_raw)}")

# ì›ë³¸ ë°ì´í„°ë¥¼ ë¨¼ì € ë¶„í• 
X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(
    X_raw, y_raw, test_size=0.2, random_state=SEED, stratify=y_raw
)

print(f"ì›ë³¸ í›ˆë ¨ ë°ì´í„°: {X_train_raw.shape}")
print(f"ì›ë³¸ ê²€ì¦ ë°ì´í„°: {X_val_raw.shape}")
print(f"ì›ë³¸ í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train_raw)}")
print(f"ì›ë³¸ ê²€ì¦ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_val_raw)}")

# =================================
# 3. ë°ì´í„° ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ!)
# =================================
def augment_data_efficientnet(X_array, y_array, target_per_class=250):
    """EfficientNetìš© ë°ì´í„° ì¦ê°• í•¨ìˆ˜"""
    
    class_0_indices = np.where(y_array == 0)[0]
    class_1_indices = np.where(y_array == 1)[0]
    
    class_0_data = [X_array[i] for i in class_0_indices]
    class_1_data = [X_array[i] for i in class_1_indices]
    
    print(f"\n=== ğŸ”„ í›ˆë ¨ ë°ì´í„° ì¦ê°• ===")
    print(f"ì¦ê°• ì „: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(class_0_data)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(class_1_data)}ê°œ")
    
    # ì–¼êµ´ í‘œì •ì— ì í•©í•œ ì¦ê°• (ë³´ìˆ˜ì )
    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.5),
        A.GaussNoise(var_limit=(10, 50), p=0.3),
    ])

    final_class_0 = class_0_data.copy()
    final_class_1 = class_1_data.copy()

    # ë¹„ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_0_data) < target_per_class:
        need_count = target_per_class - len(class_0_data)
        print(f"ë¹„ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_0_data[i % len(class_0_data)]
            # uint8ë¡œ ë³€í™˜ (Albumentations ìš”êµ¬ì‚¬í•­)
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜ [0,1] ë²”ìœ„
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_0.append(aug_img)

    # ì•½ì˜¬ë¦¬ê¸° ì¦ê°•
    if len(class_1_data) < target_per_class:
        need_count = target_per_class - len(class_1_data)
        print(f"ì•½ì˜¬ë¦¬ê¸° {need_count}ê°œ ì¦ê°• ì¤‘...")
        
        for i in tqdm(range(need_count)):
            base_img = class_1_data[i % len(class_1_data)]
            # uint8ë¡œ ë³€í™˜
            base_img_uint8 = (base_img * 255).astype(np.uint8)
            # ì¦ê°• ì ìš©
            augmented = transform(image=base_img_uint8)
            aug_img = augmented['image']
            # ë‹¤ì‹œ float32ë¡œ ë³€í™˜
            aug_img = aug_img.astype(np.float32) / 255.0
            final_class_1.append(aug_img)
    
    # ìµœì¢… ë°ì´í„°
    final_X = final_class_0 + final_class_1
    final_y = [0] * len(final_class_0) + [1] * len(final_class_1)
    
    print(f"ì¦ê°• í›„: ë¹„ì•½ì˜¬ë¦¬ê¸° {len(final_class_0)}ê°œ, ì•½ì˜¬ë¦¬ê¸° {len(final_class_1)}ê°œ")
    print(f"ì´ í›ˆë ¨ ë°ì´í„°: {len(final_X)}ê°œ")
    
    return final_X, final_y

# í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°• (ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ìœ ì§€!)
X_train_aug, y_train_aug = augment_data_efficientnet(X_train_raw, y_train_raw, target_per_class=250)

# =================================
# 4. ìµœì¢… ë°ì´í„° ì¤€ë¹„
# =================================
print(f"\n=== ğŸ“¦ ìµœì¢… ë°ì´í„° ì¤€ë¹„ ===")

# í›ˆë ¨ ë°ì´í„°: ì¦ê°•ëœ ë°ì´í„° ì‚¬ìš©
X_train = np.array(X_train_aug)
y_train = np.array(y_train_aug)

# ê²€ì¦ ë°ì´í„°: ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©
X_val = X_val_raw
y_val = y_val_raw

print(f"ìµœì¢… í›ˆë ¨ ë°ì´í„°: {X_train.shape}")
print(f"ìµœì¢… ê²€ì¦ ë°ì´í„°: {X_val.shape}")
print(f"ìµœì¢… í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train)}")
print(f"ìµœì¢… ê²€ì¦ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_val)}")

print(f"âœ… ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ê²€ì¦ ë°ì´í„°ëŠ” í›ˆë ¨ ì¤‘ ë³¸ ì  ì—†ëŠ” ì›ë³¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©")

# =================================
# 5. EfficientNet-B0 ëª¨ë¸ êµ¬ì„±
# =================================
print(f"\n=== ğŸ—ï¸ EfficientNet-B0 ì „ì´í•™ìŠµ ëª¨ë¸ êµ¬ì„± ===")

def create_efficientnet_model(input_shape=(224, 224, 3), num_classes=1):
    """EfficientNet-B0 ê¸°ë°˜ ì „ì´í•™ìŠµ ëª¨ë¸ ìƒì„±"""
    
    # ì…ë ¥ ë ˆì´ì–´
    inputs = tf.keras.Input(shape=input_shape)
    
    # EfficientNet ì „ìš© ì „ì²˜ë¦¬ (ImageNet ì •ê·œí™”)
    x = preprocess_input(inputs)
    
    # EfficientNet-B0 ë°±ë³¸ (ì‚¬ì „í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©, ë¶„ë¥˜ í—¤ë“œ ì œì™¸)
    base_model = EfficientNetB0(
        weights='imagenet',
        include_top=False,
        input_tensor=x
    )
    
    # ë°±ë³¸ ë™ê²°
    base_model.trainable = False
    
    # ë¶„ë¥˜ í—¤ë“œ êµ¬ì„±
    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.3)(x)  # ë³´ìˆ˜ì ì¸ ì •ê·œí™”
    outputs = layers.Dense(num_classes, activation='sigmoid')(x)  # ì´ì§„ë¶„ë¥˜
    
    model = tf.keras.Model(inputs, outputs)
    
    print(f"âœ… EfficientNet-B0 ë°±ë³¸ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ë°±ë³¸ ìƒíƒœ: ë™ê²°ë¨")
    print(f"   - ë¶„ë¥˜ í—¤ë“œ: GAP â†’ Dropout(0.3) â†’ Dense(1)")
    
    return model, base_model

# ëª¨ë¸ ìƒì„±
model, base_model = create_efficientnet_model()

# ëª¨ë¸ ìš”ì•½
print("\nëª¨ë¸ êµ¬ì¡°:")
model.summary()

# =================================
# 6. 1ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ
# =================================
print(f"\n=== ğŸš€ 1ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ ===")

# 1ë‹¨ê³„ ì»´íŒŒì¼
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['binary_accuracy']
)

# ì½œë°± ì„¤ì •
callbacks_stage1 = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    )
]

print("1ë‹¨ê³„ í•™ìŠµ ì‹œì‘...")
print(f"  - ë°±ë³¸: ì™„ì „ ë™ê²°")
print(f"  - í•™ìŠµë¥ : 0.001")
print(f"  - ëª©í‘œ: ë¶„ë¥˜ í—¤ë“œ ê°€ì¤‘ì¹˜ ìµœì í™”")


print(f"  - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •ì •")
class_weight = {0: 1.0, 1: 2.0}  # teasing ê°€ì¤‘ì¹˜ ì¦ê°€

# 1ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰
history_stage1 = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=32,
    callbacks=callbacks_stage1,
    class_weight=class_weight,
    verbose=1
)

# 1ë‹¨ê³„ ê²°ê³¼
stage1_loss, stage1_acc = model.evaluate(X_val, y_val, verbose=0)
print(f"\n1ë‹¨ê³„ ì™„ë£Œ:")
print(f"  - ê²€ì¦ ì •í™•ë„: {stage1_acc:.4f}")
print(f"  - ê²€ì¦ ì†ì‹¤: {stage1_loss:.4f}")

# =================================
# 7. 2ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ì¼ë¶€ í•´ì œ + ë¯¸ì„¸ì¡°ì •
# =================================
print(f"\n=== ğŸ”¬ 2ë‹¨ê³„ í•™ìŠµ: ë°±ë³¸ ì¼ë¶€ í•´ì œ + ë¯¸ì„¸ì¡°ì • ===")

# ë°±ë³¸ ì¼ë¶€ í•´ì œ (ë³´ìˆ˜ì ìœ¼ë¡œ ë§ˆì§€ë§‰ 3ê°œ ë ˆì´ì–´ë§Œ)
base_model.trainable = True

# ë§ˆì§€ë§‰ 3ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
trainable_layers = 3
for layer in base_model.layers[:-trainable_layers]:
    layer.trainable = False

print(f"ë°±ë³¸ ë ˆì´ì–´ í•´ì œ:")
print(f"  - ì „ì²´ ë ˆì´ì–´: {len(base_model.layers)}ê°œ")
print(f"  - í•´ì œ ë ˆì´ì–´: ë§ˆì§€ë§‰ {trainable_layers}ê°œ")
print(f"  - ë™ê²° ë ˆì´ì–´: {len(base_model.layers) - trainable_layers}ê°œ")

# 2ë‹¨ê³„ ì»´íŒŒì¼ (ë” ì‘ì€ í•™ìŠµë¥ )
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # 10ë°° ì‘ì€ í•™ìŠµë¥ 
    loss='binary_crossentropy',
    metrics=['binary_accuracy']
)

# ì½œë°± ì„¤ì • (ë” ë³´ìˆ˜ì )
callbacks_stage2 = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=7,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.3,
        patience=3,
        min_lr=1e-8,
        verbose=1
    )
]

print("2ë‹¨ê³„ í•™ìŠµ ì‹œì‘...")
print(f"  - ë°±ë³¸: ë§ˆì§€ë§‰ {trainable_layers}ê°œ ë ˆì´ì–´ í•´ì œ")
print(f"  - í•™ìŠµë¥ : 0.0001 (10ë°° ê°ì†Œ)")
print(f"  - ëª©í‘œ: ì–¼êµ´ í‘œì •ì— íŠ¹í™”ëœ ë¯¸ì„¸ì¡°ì •")

# 2ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰
history_stage2 = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=32,
    callbacks=callbacks_stage2,
    class_weight=class_weight, 
    verbose=1
)

# =================================
# 8. ìµœì¢… ì„±ëŠ¥ í‰ê°€
# =================================
print(f"\n=== ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ===")

# ìµœì¢… í‰ê°€
final_loss, final_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_accuracy:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {final_loss:.4f}")

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred_prob = model.predict(X_val, verbose=0)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

# ë¶„ë¥˜ ë³´ê³ ì„œ
classes = ['non_teasing', 'teasing']
print(f"\në¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_val, y_pred, target_names=classes))

# F1 Score ê³„ì‚°
f1 = f1_score(y_val, y_pred)
print(f"\nF1 Score: {f1:.4f}")

# í˜¼ë™ í–‰ë ¬
print(f"\ní˜¼ë™ í–‰ë ¬:")
cm = confusion_matrix(y_val, y_pred)
print(cm)

# ì˜ˆì¸¡ ë¶„í¬ í™•ì¸
print(f"\nì˜ˆì¸¡ ë¶„í¬:")
print(f"ì˜ˆì¸¡ í™•ë¥  ë²”ìœ„: {y_pred_prob.min():.4f} ~ {y_pred_prob.max():.4f}")
print(f"ì˜ˆì¸¡ í™•ë¥  í‘œì¤€í¸ì°¨: {y_pred_prob.std():.4f}")
print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_pred)}")

# =================================
# 9. ê²°ê³¼ ì‹œê°í™”
# =================================
print(f"\n=== ğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ===")

# ë‘ ë‹¨ê³„ í•™ìŠµ ê³¼ì • ì‹œê°í™”
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1ë‹¨ê³„ ì •í™•ë„
axes[0,0].plot(history_stage1.history['binary_accuracy'], label='Stage 1 Training', color='blue')
axes[0,0].plot(history_stage1.history['val_binary_accuracy'], label='Stage 1 Validation', color='orange')
if 'binary_accuracy' in history_stage2.history:
    stage1_epochs = len(history_stage1.history['binary_accuracy'])
    stage2_epochs = range(stage1_epochs, stage1_epochs + len(history_stage2.history['binary_accuracy']))
    axes[0,0].plot(stage2_epochs, history_stage2.history['binary_accuracy'], label='Stage 2 Training', color='green')
    axes[0,0].plot(stage2_epochs, history_stage2.history['val_binary_accuracy'], label='Stage 2 Validation', color='red')
axes[0,0].axhline(y=0.5, color='gray', linestyle='--', label='Random Baseline')
axes[0,0].axvline(x=len(history_stage1.history['binary_accuracy']), color='purple', linestyle=':', label='Stage Transition')
axes[0,0].set_title('Model Accuracy (2-Stage Training)')
axes[0,0].set_xlabel('Epoch')
axes[0,0].set_ylabel('Accuracy')
axes[0,0].legend()
axes[0,0].grid(True)

# 1ë‹¨ê³„ ì†ì‹¤
axes[0,1].plot(history_stage1.history['loss'], label='Stage 1 Training', color='blue')
axes[0,1].plot(history_stage1.history['val_loss'], label='Stage 1 Validation', color='orange')
if 'loss' in history_stage2.history:
    stage1_epochs = len(history_stage1.history['loss'])
    stage2_epochs = range(stage1_epochs, stage1_epochs + len(history_stage2.history['loss']))
    axes[0,1].plot(stage2_epochs, history_stage2.history['loss'], label='Stage 2 Training', color='green')
    axes[0,1].plot(stage2_epochs, history_stage2.history['val_loss'], label='Stage 2 Validation', color='red')
axes[0,1].axvline(x=len(history_stage1.history['loss']), color='purple', linestyle=':', label='Stage Transition')
axes[0,1].set_title('Model Loss (2-Stage Training)')
axes[0,1].set_xlabel('Epoch')
axes[0,1].set_ylabel('Loss')
axes[0,1].legend()
axes[0,1].grid(True)

# í˜¼ë™ í–‰ë ¬ íˆíŠ¸ë§µ
import seaborn as sns
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
           xticklabels=classes, yticklabels=classes, ax=axes[1,0])
axes[1,0].set_title('Confusion Matrix')
axes[1,0].set_xlabel('Predicted')
axes[1,0].set_ylabel('Actual')

# ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
axes[1,1].hist(y_pred_prob[y_val==0], alpha=0.5, label='non_teasing', bins=20, color='blue')
axes[1,1].hist(y_pred_prob[y_val==1], alpha=0.5, label='teasing', bins=20, color='orange')
axes[1,1].axvline(x=0.5, color='red', linestyle='--', label='Decision Threshold')
axes[1,1].set_title('Prediction Probability Distribution')
axes[1,1].set_xlabel('Predicted Probability')
axes[1,1].set_ylabel('Count')
axes[1,1].legend()
axes[1,1].grid(True)

plt.tight_layout()
plt.show()

# =================================
# 10. ì„±ëŠ¥ ê°œì„  ë¶„ì„
# =================================
print(f"\n=== ğŸ¯ ì„±ëŠ¥ ê°œì„  ë¶„ì„ ===")

baseline_accuracy = 0.775  # ê¸°ë³¸ CNN ì„±ëŠ¥
improvement = final_accuracy - baseline_accuracy
improvement_percent = (improvement / baseline_accuracy) * 100

print(f"âœ… EfficientNet-B0 ì „ì´í•™ìŠµ ê²°ê³¼:")
print(f"   - ê¸°ë³¸ CNN: 77.5%")
print(f"   - EfficientNet: {final_accuracy:.1%}")
print(f"   - ê°œì„ í­: {improvement:+.1%} ({improvement_percent:+.1f}%)")
print(f"   - F1 Score: {f1:.4f}")
print(f"   - ì´ í•™ìŠµ ì—í¬í¬: {len(history_stage1.history['loss']) + len(history_stage2.history['loss'])}íšŒ")

if final_accuracy > 0.82:
    print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! ì „ì´í•™ìŠµì´ ë§¤ìš° íš¨ê³¼ì ")
elif final_accuracy > 0.80:
    print(f"ğŸ‘ ëª©í‘œ ê·¼ì ‘! ì „ì´í•™ìŠµ íš¨ê³¼ í™•ì¸")
elif final_accuracy > baseline_accuracy:
    print(f"âœ¨ ì„±ëŠ¥ í–¥ìƒ! ì „ì´í•™ìŠµ ë„ì›€ë¨")
else:
    print(f"ğŸ¤” ì„±ëŠ¥ ì •ì²´. ì¶”ê°€ ì¡°ì • í•„ìš”")

print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:")
if final_accuracy < 0.80:
    print(f"   - ë°ì´í„° ìˆ˜ì§‘ í™•ëŒ€")
    print(f"   - VGGFace2 ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‹œë„")
    print(f"   - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
else:
    print(f"   - ëª¨ë¸ ì•™ìƒë¸” ì‹œë„")
    print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… ê²€ì¦")
    print(f"   - ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ê³ ë ¤")

print(f"\nğŸš€ EfficientNet-B0 ì „ì´í•™ìŠµ ì™„ë£Œ!")
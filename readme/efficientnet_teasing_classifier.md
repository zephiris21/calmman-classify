# EfficientNet ì–¼êµ´í‘œì • ë¶„ë¥˜ê¸°

> **í‚¹ë°›ëŠ”ì‚¬ì§„ vs í‰ë²”í•œì‚¬ì§„** ê°ì • ìƒíƒœë¥¼ ìë™ ë¶„ë¥˜í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸


## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
- [ì£¼ìš” íŠ¹ì§•](#-ì£¼ìš”-íŠ¹ì§•)
- [ì„¤ì¹˜ ë° í™˜ê²½ì„¤ì •](#-ì„¤ì¹˜-ë°-í™˜ê²½ì„¤ì •)
- [ë°ì´í„° êµ¬ì¡°](#-ë°ì´í„°-êµ¬ì¡°)
- [ëª¨ë¸ ì•„í‚¤í…ì²˜](#-ëª¨ë¸-ì•„í‚¤í…ì²˜)
- [ì‚¬ìš©ë²•](#-ì‚¬ìš©ë²•)
- [ì„±ëŠ¥ ë° ê²°ê³¼](#-ì„±ëŠ¥-ë°-ê²°ê³¼)
- [ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­](#-ê¸°ìˆ ì -ì„¸ë¶€ì‚¬í•­)
- [ë¬¸ì œí•´ê²°](#-ë¬¸ì œí•´ê²°)

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **EfficientNet-B0** ê¸°ë°˜ ì „ì´í•™ìŠµì„ í™œìš©í•˜ì—¬ ì–¼êµ´ í‘œì •ì—ì„œ **ì•½ì˜¬ë¦¬ê¸°(teasing)**ì™€ **ë¹„ì•½ì˜¬ë¦¬ê¸°(non-teasing)** ê°ì • ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ
- ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì•½ì˜¬ë¦¬ê¸° ì˜ë„ ê°ì§€
- ì‹¤ì‹œê°„ ê°ì • ìƒíƒœ ë¶„ë¥˜
- ë†’ì€ ì •í™•ë„ì™€ íš¨ìœ¨ì ì¸ ì¶”ë¡  ì†ë„ ë‹¬ì„±

## âœ¨ ì£¼ìš” íŠ¹ì§•

### ğŸ”¬ **ì „ì´í•™ìŠµ ê¸°ë°˜**
- **ImageNet** ì‚¬ì „í•™ìŠµëœ EfficientNet-B0 í™œìš©
- **2ë‹¨ê³„ í•™ìŠµ**: ë°±ë³¸ ë™ê²° â†’ ë¯¸ì„¸ì¡°ì •
- ì†Œê·œëª¨ ë°ì´í„°ì…‹ì—ì„œë„ ë†’ì€ ì„±ëŠ¥

### ğŸ›¡ï¸ **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**
- í›ˆë ¨/ê²€ì¦ ë°ì´í„° ì‚¬ì „ ë¶„í• 
- ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
- ì¦ê°•ì€ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ì ìš©

### âš–ï¸ **í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°**
- ë°ì´í„° ì¦ê°•ìœ¼ë¡œ í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
- í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš© ì˜µì…˜
- F1 Score ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€

### ğŸ¨ **ì‹œê°í™” ë° ë¶„ì„**
- í•™ìŠµ ê³¼ì • ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°ì  ë¶„ì„
- í˜¼ë™í–‰ë ¬ ë° í™•ë¥  ë¶„í¬ ì‹œê°í™”

## ğŸ› ï¸ ì„¤ì¹˜ ë° í™˜ê²½ì„¤ì •

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Python 3.9+
- CUDA ì§€ì› GPU (ê¶Œì¥)
- ìµœì†Œ 8GB RAM

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/your-username/calmman-facial-classification.git
cd calmman-facial-classification
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„±
```bash
# Windows
python -m venv calm-env
calm-env\Scripts\activate

# Linux/Mac
python -m venv calm-env
source calm-env/bin/activate
```

### 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

#### ì£¼ìš” íŒ¨í‚¤ì§€
```txt
tensorflow>=2.15.0
opencv-python>=4.8.0
albumentations>=1.3.1
scikit-learn>=1.3.0
matplotlib>=3.7.2
seaborn>=0.12.2
tqdm>=4.66.1
numpy>=1.24.3
pillow>=10.0.0
```

## ğŸ“ ë°ì´í„° êµ¬ì¡°

```
data/
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ teasing/          # ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ non_teasing/      # ë¹„ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€
â”‚   â””â”€â”€ test_image/       # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€
â””â”€â”€ raw/                  # ì›ë³¸ ë°ì´í„° (ì„ íƒì‚¬í•­)
```

### ë°ì´í„° ìš”êµ¬ì‚¬í•­
- **ì´ë¯¸ì§€ í˜•ì‹**: JPG, PNG, BMP, TIFF, WebP
- **ê¶Œì¥ í¬ê¸°**: ìµœì†Œ 224x224 í”½ì…€
- **í›ˆë ¨ ë°ì´í„°**: í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 50ê°œ ì´ìƒ ê¶Œì¥

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### EfficientNet-B0 ë°±ë³¸
```
ì…ë ¥ (224, 224, 3)
    â†“
EfficientNet ì „ì²˜ë¦¬
    â†“
EfficientNet-B0 ë°±ë³¸ (ImageNet ì‚¬ì „í•™ìŠµ)
    â†“
Global Average Pooling 2D
    â†“
Dropout (0.3)
    â†“
Dense(1, activation='sigmoid')
    â†“
ì¶œë ¥ (ì´ì§„ ë¶„ë¥˜ í™•ë¥ )
```

### í›ˆë ¨ ì „ëµ
1. **1ë‹¨ê³„**: ë°±ë³¸ ì™„ì „ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ
2. **2ë‹¨ê³„**: ë°±ë³¸ ë§ˆì§€ë§‰ 3ê°œ ë ˆì´ì–´ í•´ì œ + ë¯¸ì„¸ì¡°ì •

## ğŸš€ ì‚¬ìš©ë²•

### Jupyter Notebook ì‹¤í–‰
```bash
jupyter notebook notebooks/efficientnet_teasing-v1.ipynb
```

### ì…€ ì‹¤í–‰ ìˆœì„œ
1. **ì…€ 1-2**: ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° í•¨ìˆ˜ ì •ì˜
2. **ì…€ 3-7**: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
3. **ì…€ 8-10**: ëª¨ë¸ êµ¬ì„± ë° ì„¤ì •
4. **ì…€ 11-14**: 2ë‹¨ê³„ í›ˆë ¨ ì‹¤í–‰
5. **ì…€ 15-17**: ì„±ëŠ¥ í‰ê°€ ë° ì‹œê°í™”
6. **ì…€ 18-21**: í…ŒìŠ¤íŠ¸ ë° ëª¨ë¸ ì €ì¥

### ì£¼ìš” ì„¤ì • ë³€ê²½
```python
# ë°ì´í„° ê²½ë¡œ (ì…€ 3)
base_path = r'D:\your_project_path\data\processed'

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ì…€ 10)
class_weight = {0: 1.0, 1: 2.0}  # teasing ê°€ì¤‘ì¹˜ ì¦ê°€

# ë°ì´í„° ì¦ê°•ëŸ‰ (ì…€ 5)
target_per_class = 250  # í´ë˜ìŠ¤ë‹¹ ëª©í‘œ ë°ì´í„° ìˆ˜
```

### ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©
```python
import tensorflow as tf

# ëª¨ë¸ ë¡œë“œ
model = tf.keras.models.load_model('models/efficientnet_teasing_classifier.h5')

# ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
img = cv2.imread('test_image.jpg')
img = cv2.resize(img, (224, 224))
img = img.astype('float32')
prediction = model.predict(np.expand_dims(img, axis=0))

# ê²°ê³¼ í•´ì„
probability = prediction[0][0]
result = "ì•½ì˜¬ë¦¬ê¸°" if probability > 0.5 else "ë¹„ì•½ì˜¬ë¦¬ê¸°"
confidence = probability if probability > 0.5 else 1 - probability

print(f"ì˜ˆì¸¡: {result} (í™•ì‹ ë„: {confidence:.2f})")
```

## ğŸ“Š ì„±ëŠ¥ ë° ê²°ê³¼

### ìµœì¢… ì„±ëŠ¥ ì§€í‘œ
- **ì •í™•ë„**: 82.5%
- **F1 Score**: 0.74
- **í–¥ìƒë„**: ê¸°ë³¸ CNN ëŒ€ë¹„ +5.0%p (+6.5%)

### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
| í´ë˜ìŠ¤ | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| ë¹„ì•½ì˜¬ë¦¬ê¸° | 0.79 | 0.96 | 0.87 | 24 |
| ì•½ì˜¬ë¦¬ê¸° | 0.91 | 0.62 | 0.74 | 16 |
| **í‰ê· ** | **0.84** | **0.82** | **0.82** | **40** |

### í˜¼ë™ í–‰ë ¬
```
              ì˜ˆì¸¡
ì‹¤ì œ    ë¹„ì•½ì˜¬ë¦¬ê¸°  ì•½ì˜¬ë¦¬ê¸°
ë¹„ì•½ì˜¬ë¦¬ê¸°    23       1
ì•½ì˜¬ë¦¬ê¸°       6      10
```

### í•™ìŠµ íŠ¹ì„±
- **ì´ ì—í¬í¬**: 57íšŒ (1ë‹¨ê³„ + 2ë‹¨ê³„)
- **ì¡°ê¸° ì¢…ë£Œ**: ê²€ì¦ ì†ì‹¤ ê¸°ë°˜
- **í•™ìŠµë¥  ê°ì†Œ**: ì ì‘ì  ì¡°ì •
- **ì •ê·œí™”**: Dropout 0.3

## ğŸ”§ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### ë°ì´í„° ì¦ê°• ê¸°ë²•
```python
transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
    A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=10, p=0.5),
    A.GaussNoise(var_limit=(10, 50), p=0.3),
])
```

### ì „ì´í•™ìŠµ ì „ëµ
1. **ì‚¬ì „í•™ìŠµ**: ImageNetì—ì„œ ì¼ë°˜ì  ì‹œê°ì  íŠ¹ì§• í•™ìŠµ
2. **ë°±ë³¸ ë™ê²°**: ì €ìˆ˜ì¤€ íŠ¹ì§• ë³´ì¡´
3. **ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ**: ì–¼êµ´ í‘œì • íŠ¹í™” íŠ¹ì§• í•™ìŠµ
4. **ë¯¸ì„¸ì¡°ì •**: ê³ ìˆ˜ì¤€ íŠ¹ì§• ì ì‘

### í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ íš¨ê³¼
- **ê¸°ë³¸**: {0: 1.0, 1: 1.0} â†’ 80.0% ì •í™•ë„
- **ì¡°ì •**: {0: 1.0, 1: 2.0} â†’ 82.5% ì •í™•ë„
- **ê°œì„ **: teasing ì¬í˜„ìœ¨ 56% â†’ 62.5%

### ë©”ëª¨ë¦¬ ìµœì í™”
- **ë°°ì¹˜ í¬ê¸°**: 32 (GPU ë©”ëª¨ë¦¬ ê³ ë ¤)
- **ì´ë¯¸ì§€ í¬ê¸°**: 224x224 (EfficientNet ìµœì  í¬ê¸°)
- **ë°ì´í„° íƒ€ì…**: float32 (ì •ë°€ë„/ì†ë„ ê· í˜•)

## ğŸ› ï¸ ë¬¸ì œí•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
```python
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
batch_size = 16  # ê¸°ë³¸ê°’ 32ì—ì„œ ê°ì†Œ

# ë˜ëŠ” ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ (ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
img_size = 192  # ê¸°ë³¸ê°’ 224ì—ì„œ ê°ì†Œ
```

#### 2. **CUDA ì˜¤ë¥˜**
```bash
# CPU ëª¨ë“œë¡œ ê°•ì œ ì‹¤í–‰
export CUDA_VISIBLE_DEVICES=""
```

#### 3. **í•œê¸€ ê²½ë¡œ ë¬¸ì œ**
```python
# PILë¡œ ì´ë¯¸ì§€ ë¡œë“œ
from PIL import Image
pil_img = Image.open(img_path)
img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
```

#### 4. **ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨**
```python
# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
model_path = r'D:\full\path\to\model.h5'
model = tf.keras.models.load_model(model_path)
```

### ì„±ëŠ¥ ê°œì„  ë°©ë²•

#### 1. **ë°ì´í„° í’ˆì§ˆ í–¥ìƒ**
- ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì‚¬ìš©
- ë‹¤ì–‘í•œ ì¡°ëª…/ê°ë„ ë°ì´í„° ìˆ˜ì§‘
- ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ì œê±°

#### 2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
```python
# í•™ìŠµë¥  ì¡°ì •
learning_rate_stage1 = 0.002  # ê¸°ë³¸: 0.001
learning_rate_stage2 = 0.0002  # ê¸°ë³¸: 0.0001

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
class_weight = {0: 1.0, 1: 3.0}  # ë” ê°•í•œ ê°€ì¤‘ì¹˜

# ì¦ê°• ê°•ë„ ì¡°ì •
target_per_class = 300  # ë” ë§ì€ ì¦ê°• ë°ì´í„°
```

#### 3. **ëª¨ë¸ ì•™ìƒë¸”**
```python
# ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©
models = [model1, model2, model3]
predictions = [model.predict(X) for model in models]
ensemble_pred = np.mean(predictions, axis=0)
```



## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
- [Facial Expression Recognition in Online Learning](https://ieeexplore.ieee.org/document/9846390)

### ê¸°ìˆ  ë¬¸ì„œ
- [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Albumentations Documentation](https://albumentations.ai/docs/)

### ê´€ë ¨ í”„ë¡œì íŠ¸
- [FER2013 Challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge)
- [AffectNet Dataset](http://mohammadmahoor.com/affectnet/)


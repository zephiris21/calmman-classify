# EfficientNet-B0 PyTorch ì „ì´í•™ìŠµ ì´ì§„ë¶„ë¥˜ ì‹œìŠ¤í…œ - ì„¤ëª…ì„œ

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” **PyTorchì™€ EfficientNet-B0**ì„ í™œìš©í•œ ì „ì´í•™ìŠµ ê¸°ë°˜ ì–¼êµ´ í‘œì • ì´ì§„ë¶„ë¥˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì¹¨ì°©ë§¨ì˜ "ì•½ì˜¬ë¦¬ê¸° vs ë¹„ì•½ì˜¬ë¦¬ê¸°" í‘œì •ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•**:
- ImageNet ì‚¬ì „í›ˆë ¨ëœ EfficientNet-B0 ë°±ë³¸ í™œìš©
- 2ë‹¨ê³„ ì „ì´í•™ìŠµ (ë°±ë³¸ ë™ê²° â†’ ì ì§„ì  í•´ì œ)
- Mixed Precision Trainingìœ¼ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”
- í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ë° ë°ì´í„° ì¦ê°•

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### í™˜ê²½ ìš”êµ¬ì‚¬í•­
```bash
pip install torch torchvision timm albumentations scikit-learn matplotlib seaborn tqdm pillow opencv-python
```

### ê¸°ë³¸ ì‹¤í–‰
```bash
# ì½”ë“œ íŒŒì¼ ì‹¤í–‰
python torch_eff_classifier.py
```

### ë°ì´í„° êµ¬ì¡°
```
data/processed/
â”œâ”€â”€ teasing/          # ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ë“¤
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ non_teasing/      # ë¹„ì•½ì˜¬ë¦¬ê¸° ì´ë¯¸ì§€ë“¤
    â”œâ”€â”€ image1.jpg
    â””â”€â”€ ...
```

## ğŸ§  ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. ì „ì²´ íŒŒì´í”„ë¼ì¸

```
ë°ì´í„° ë¡œë”© â†’ ì „ì²˜ë¦¬ â†’ 2ë‹¨ê³„ ì „ì´í•™ìŠµ â†’ ì„±ëŠ¥ í‰ê°€ â†’ ê²°ê³¼ ì €ì¥
     â†“           â†“           â†“            â†“          â†“
   ì›ë³¸ë¶„í•    â†’  ì¦ê°•ì²˜ë¦¬  â†’  ë°±ë³¸ë™ê²°    â†’  ê²€ì¦    â†’  ì‹œê°í™”
                           â†’  ë¯¸ì„¸ì¡°ì •
```

### 2. ëª¨ë¸ êµ¬ì¡° (EfficientNetClassifier)

```python
class EfficientNetClassifier(nn.Module):
    def __init__(self):
        # ë°±ë³¸: timm.efficientnet_b0 (ImageNet ì‚¬ì „í›ˆë ¨)
        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)
        
        # ë¶„ë¥˜ í—¤ë“œ: Dropout + Linear
        self.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(feature_dim, 2)  # ì´ì§„ë¶„ë¥˜
        )
```

**ì¥ì **:
- **ê²½ëŸ‰ì„±**: EfficientNet-B0ëŠ” íŒŒë¼ë¯¸í„° íš¨ìœ¨ì 
- **ì„±ëŠ¥**: ImageNet ì‚¬ì „í›ˆë ¨ìœ¼ë¡œ ê°•ë ¥í•œ íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥
- **ìœ ì—°ì„±**: ë°±ë³¸ê³¼ ë¶„ë¥˜ í—¤ë“œ ë¶„ë¦¬ë¡œ ë‹¨ê³„ë³„ í•™ìŠµ ê°€ëŠ¥

## ğŸ“Š 2ë‹¨ê³„ ì „ì´í•™ìŠµ ì „ëµ

### Stage 1: ë°±ë³¸ ë™ê²° + ë¶„ë¥˜ í—¤ë“œ í•™ìŠµ
```python
# ë°±ë³¸ ì™„ì „ ë™ê²°
model.freeze_backbone()

# ë¶„ë¥˜ í—¤ë“œë§Œ í•™ìŠµ
optimizer_stage1 = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)

# 15 ì—í¬í¬ í•™ìŠµ
```

**ëª©ì **: ìƒˆë¡œìš´ ë„ë©”ì¸(ì–¼êµ´ í‘œì •)ì— ë§ëŠ” ë¶„ë¥˜ í—¤ë“œë¥¼ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ

### Stage 2: ë°±ë³¸ ì¼ë¶€ í•´ì œ + ë¯¸ì„¸ì¡°ì •
```python
# ë§ˆì§€ë§‰ 3ê°œ ë¸”ë¡ë§Œ í•´ì œ
model.unfreeze_backbone(layers_to_unfreeze=3)

# ë” ì‘ì€ í•™ìŠµë¥ ë¡œ ë¯¸ì„¸ì¡°ì •
optimizer_stage2 = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)

# 20 ì—í¬í¬ ë¯¸ì„¸ì¡°ì •
```

**ëª©ì **: ë„ë©”ì¸ íŠ¹í™” íŠ¹ì§•ì„ í•™ìŠµí•˜ë©´ì„œ ì‚¬ì „í›ˆë ¨ëœ ì§€ì‹ ë³´ì¡´

## ğŸ”§ í•µì‹¬ ìµœì í™” ê¸°ë²•

### 1. ë°ì´í„° ì¦ê°• ë° ë¶ˆê· í˜• í•´ê²°
```python
# Albumentations ë°ì´í„° ì¦ê°•
transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.HueSaturationValue(p=0.5),
    A.GaussNoise(p=0.3)
])

# í´ë˜ìŠ¤ë³„ ê· í˜• ë§ì¶”ê¸° (ê° í´ë˜ìŠ¤ 250ê°œë¡œ ì¦ê°•)
X_train_aug, y_train_aug = augment_data_pytorch(X_train_raw, y_train_raw, target_per_class=250)

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
class_weights = torch.tensor([1.0, 2.0])  # teasing í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€
```

### 2. Mixed Precision Training
```python
# GPU ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”
scaler = GradScaler()

with autocast():
    outputs = model(images)
    loss = criterion(outputs, labels)

scaler.scale(loss).backward()
scaler.step(optimizer)
```

### 3. ì¡°ê¸° ì¢…ë£Œ ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
```python
# ì„±ëŠ¥ ì •ì²´ ì‹œ ìë™ ì¢…ë£Œ
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)

# ê²€ì¦ ì†ì‹¤ ê¸°ì¤€ ì¡°ê¸° ì¢…ë£Œ
if patience_counter >= patience:
    break
```

## ğŸ“ˆ ë°ì´í„° íë¦„

### 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
```python
# 1. ì›ë³¸ ë°ì´í„° ë¡œë”©
X_non_teasing, y_non_teasing = load_images_robust(non_teasing_path, 0)
X_teasing, y_teasing = load_images_robust(teasing_path, 1)

# 2. ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•œ ì›ë³¸ ë¶„í• 
X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(X, y, test_size=0.2, stratify=y)

# 3. í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°• (ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ìœ ì§€)
X_train_aug, y_train_aug = augment_data_pytorch(X_train_raw, y_train_raw)
```

### 2. PyTorch Dataset & DataLoader
```python
# Transform ì •ì˜
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”
])

# Dataset ìƒì„±
train_dataset = FacialExpressionDataset(X_train_aug, y_train_aug, transform=train_transform)
val_dataset = FacialExpressionDataset(X_val_raw, y_val_raw, transform=val_transform)

# DataLoader ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)
```

## ğŸ¯ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 1. ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë‹ˆí„°ë§
```python
def train_epoch(model, train_loader, criterion, optimizer, scaler, device):
    model.train()
    
    pbar = tqdm(train_loader, desc="Training")
    for batch_idx, (images, labels) in enumerate(pbar):
        # Mixed Precision Training
        with autocast():
            outputs = model(images)
            loss = criterion(outputs, labels)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        pbar.set_postfix({
            'Loss': f'{running_loss/(batch_idx+1):.4f}',
            'Acc': f'{100.*correct/total:.2f}%'
        })
```

### 2. ë‹¤ì¤‘ ì§€í‘œ í‰ê°€
```python
# ë¶„ë¥˜ ì„±ëŠ¥ ì§€í‘œ
f1 = f1_score(final_labels, final_predictions)
precision = precision_score(final_labels, final_predictions)
recall = recall_score(final_labels, final_predictions)

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(final_labels, final_predictions)
```

## ğŸ“Š ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥

### 1. í•™ìŠµ ê³¼ì • ì‹œê°í™”
- **2ë‹¨ê³„ í•™ìŠµ ê³¡ì„ **: ì •í™•ë„/ì†ì‹¤ ë³€í™” ì¶”ì´
- **í˜¼ë™ í–‰ë ¬**: ë¶„ë¥˜ ì„±ëŠ¥ ì„¸ë¶€ ë¶„ì„
- **ì˜ˆì¸¡ í™•ë¥  ë¶„í¬**: ëª¨ë¸ ì‹ ë¢°ë„ ë¶„ì„

### 2. ìë™ ê²°ê³¼ ì €ì¥
```
results/pytorch_efficientnet/
â”œâ”€â”€ models/                    # í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ best_model_stage1_*.pth
â”‚   â”œâ”€â”€ best_model_stage2_*.pth
â”‚   â””â”€â”€ final_model_*.pth
â”œâ”€â”€ plots/                     # ì‹œê°í™” ê·¸ë˜í”„
â”œâ”€â”€ metrics/                   # ì„±ëŠ¥ ìš”ì•½ í…ìŠ¤íŠ¸
â””â”€â”€ logs/                      # ìƒì„¸ í•™ìŠµ ë¡œê·¸ (JSON)
```

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •

| êµ¬ë¶„ | Stage 1 | Stage 2 | ì„¤ëª… |
|------|---------|---------|------|
| **í•™ìŠµë¥ ** | 0.001 | 0.0001 | ë¯¸ì„¸ì¡°ì • ì‹œ 10ë°° ê°ì†Œ |
| **ì—í¬í¬** | 15 | 20 | ì¡°ê¸° ì¢…ë£Œë¡œ ìë™ ì¡°ì ˆ |
| **ë°°ì¹˜ í¬ê¸°** | 32 | 32 | GPU ë©”ëª¨ë¦¬ ê³ ë ¤ |
| **Dropout** | 0.3 | 0.3 | ê³¼ì í•© ë°©ì§€ |
| **ê°€ì¤‘ì¹˜ ê°ì‡ ** | 1e-4 | 1e-4 | ì •ê·œí™” |

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
batch_size = 16  # ë˜ëŠ” 8

# Mixed Precision í™œìš©
scaler = GradScaler()
```

### ì„±ëŠ¥ ì €í•˜
```python
# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
class_weights = torch.tensor([1.0, 3.0])  # ì†Œìˆ˜ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€

# ë°ì´í„° ì¦ê°• ê°•í™”
target_per_class = 500  # ì¦ê°• ë°ì´í„° ìˆ˜ ì¦ê°€
```

### ê³¼ì í•©
```python
# Dropout ì¦ê°€
dropout_rate = 0.5

# ì¡°ê¸° ì¢…ë£Œ patience ê°ì†Œ
patience = 3
```

## ğŸ“ˆ ê¸°ëŒ€ ì„±ëŠ¥

**ëª©í‘œ ì„±ëŠ¥**:
- ê²€ì¦ ì •í™•ë„: **85%** ì´ìƒ
- F1 Score: **0.85** ì´ìƒ
- ê¸°ì¡´ TensorFlow ëª¨ë¸ ëŒ€ë¹„ **5-10%** í–¥ìƒ

**ì„±ëŠ¥ ê°œì„  ìš”ì¸**:
1. **EfficientNet-B0**: íŒŒë¼ë¯¸í„° íš¨ìœ¨ì ì¸ ì•„í‚¤í…ì²˜
2. **2ë‹¨ê³„ ì „ì´í•™ìŠµ**: ì•ˆì •ì ì¸ í•™ìŠµ ê³¼ì •
3. **Mixed Precision**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„±
4. **ë°ì´í„° ì¦ê°•**: ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

## ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

### ì„±ëŠ¥ì´ ëª©í‘œì— ë¯¸ë‹¬í•  ê²½ìš°
- **VGGFace2 ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ì ìš©** (ë…¼ë¬¸ ê¸°ë²•)
- **ê°•ê±´í•œ ìµœì í™”(Robust Optimization) ë„ì…** (ë…¼ë¬¸ Algorithm 1)
- **ì•™ìƒë¸” ëª¨ë¸** êµ¬ì„±
- **ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘** ë° ë¼ë²¨ë§ í’ˆì§ˆ ê°œì„ 

### ì„±ëŠ¥ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•œ ê²½ìš°
- **ì‹¤ì œ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ í†µí•©**
- **ëª¨ë¸ ê²½ëŸ‰í™”** (ëª¨ë°”ì¼ ë°°í¬ ê³ ë ¤)
- **ì˜¨ë¼ì¸ í•™ìŠµ** ê¸°ëŠ¥ ì¶”ê°€
- **ë‹¤ì¤‘ ê°ì • ë¶„ë¥˜**ë¡œ í™•ì¥

ì´ ì‹œìŠ¤í…œì€ ë…¼ë¬¸ì˜ ì´ë¡ ì  ê¸°ë°˜ì„ ì‹¤ìš©ì ì¸ PyTorch êµ¬í˜„ìœ¼ë¡œ ë°œì „ì‹œí‚¨ ì‚¬ë¡€ë¡œ, ì „ì´í•™ìŠµì˜ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ì—¬ ë†’ì€ ë¶„ë¥˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.